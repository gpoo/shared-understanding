\chapter{Discussion}

In the previous chapter I presented an argument that looks at coordination and communication as the central problem of current software development, and explained that coordination and communication cannot usefully be conceived in a simplistic manner in our domain. Instead, I presented a characterization based on the concept of shared understanding. I argued that coordination, effectively, consists of sharing an understanding about the goals and plans of the participants of the situation, and that communication, similarly, consists of sharing an understanding about the status and context of their situation. I then described several characteristics of interaction that enable or simplify the formation of shared understanding: synchrony, proximity, proportionality, and maturity. I argued that organizational strategies that foster these attributes lead to a more robust shared understanding, and therefore to more effective coordination and communication.

I then used this argument to revisit several common constructs in software research and explore the ways in which they are altered once we recognize the challenges of successful coordination and communication. Some of these constructs, such as processes, documentation, and organizational growth, are detrimental or ineffective to achieve coordination and communication; some others, such as some practices, tools, and the appropriate use of space, can be extremely valuable. It is not, I argued, that processes or documentation are simply \emph{wrong} or that practices and tools are \emph{right}. Rather, the problem is that processes and documentation tend to rely on ineffective mechanisms to coordinate or communicate, such as asynchronous, distant, and disproportionate goal and plan setting, in the case of project lifecycle processes, and asynchronous, distant, and disproportionate communication of information, in the case of documentation. Some practices and tools, in contrast, foster synchronous, proximate, proportionate, and mature activities, so that coordination and communication efforts have greater chances of success. Of course, this distinction only matters when organizations have a choice. If the only mechanisms available to an organization are asynchronous, distant, disproportionate, and immature, then it does not matter if some hypothetical alternative would be better: it can only choose among those alternatives that are truly available. 

If my earlier arguments are correct, an emphasis in the development of shared understanding and on the shared understanding criteria is beneficial for software researchers and practitioners. However, such an approach raises several questions that need to be addressed. The rather complex conceptualization of coordination and communication used in this work creates several practical and theoretical challenges, and its linkages to other current research approaches is not clear. In this chapter I address these challenges and links to current work.



\section{Practical challenges}

Analyzing software development with a shared understanding perspective creates several practical challenges. First of all is the added complexity of the constructs of this theory. Much current software research assumes a simple model of coordination (see section \ref{sec:ProcessEngineering}) and communication (see section \ref{sec:InfoFlow}). But when we cannot assume, for instance, that interaction events are equivalent to successful communication, we end up with a more difficult domain that is less amenable to statistical tests or data mining. Thus this gain in the correctness of the constructs appears to come with a loss of research opportunities. I believe it only \emph{appears} this way, however, since ignoring the essential complexities of coordination and communication (that is, using an incorrect if simple model) misleads our research results anyway \cite{Aranda2009}. We must learn to deal with complex constructs if we are to progress.

A second challenge is measuring, or even assessing, a concept such as ``shared understanding.'' Easterbrook \shortcite{Easterbrook1994} has pointed out the near-impossibility of assessing that two people have enough of a shared understanding: we can see in events of breakdown that their understanding has not been fully shared, but the absence of a breakdown does not imply a full shared understanding.\footnote{A useful analogy is software defects: the absence of detected errors does not ensure the absence of defects.} Furthermore, Easterbrook uses an abstract conceptualization of mental models in his discussion, while this thesis is concerned with a wide variety of more concrete kinds of knowledge, such as plans, goals, status, and context; this variety of elements, as well as the tacit nature of several of them, make it difficult to use any one instrument, should it exist, to provide a comprehensive assessment of shared understanding between any two individuals.\footnote{Just as standard software quality tests are unsatisfactory means to assess true software quality \cite{Pipitone2010}.} Finally, in this thesis I focus on developing a robust shared understanding at an organizational level, so that the general state of robustness of the shared understanding of the organization is relevant while single events of breakdown and harmonization tell us little about the general state of the organization.\footnote{To use the analogy one last time, (the absence of) single defects, or defects localized in one module, are not necessarily indicative the software quality of the application they conform.}

Even assuming we overcame the challenge of assessing the robustness of shared understanding in a software organization, we would also need to establish their effectiveness in software development projects. This thesis claims that sharing an understanding leads to greater success, but our standard metrics of success may be inappropriate. For instance, a focus on profit makes little sense for organizations whose members hold more immaterial values; a focus on longevity does not properly account for start-ups aiming to be acquired by larger corporations and to cash in on the acquisition. Success in an ``open-natural system'' organization is the achievement of the goals of the members of the organization, but people associate in software organizations for a variety of possible reasons, and two organizations may well have non-comparable goals. Generalizing on one variable is inappropriate. However, we should consider that this is not a practical challenge merely for the shared understanding theory, but in general for the study of software development. Several proxies for success have been used in the past (programming speed, effort, adherence to schedules, job satisfaction, client satisfaction, turnover, and profit, among others); their appropriateness depends on the extent to which they are valued by the members of each organization, and should be assessed on a case-by-case basis.

These considerations seem to offer us two complementary alternatives. First, we may execute rich qualitative studies that provide us with insights about the concepts of this theory and their relationships, assessing whether practices, tools, or other elements are theoretically and practically advantageous for particular software organizations. While I am fond of this approach, and while it is epistemologically sound, it is not yet very dear to the software research community, which prefers a more quantitative foundation to its findings.

The alternative is to use proxies for shared understanding, refining the proxies as our knowledge of their deficiencies increases. An example of such a proxy would be the development of indices of synchrony, proximity, proportionality, and maturity in group activities, informed by an assessment of group cohesion derived from social networks analysis: an organization would have a high score if it is cohesive and its strategies rank high in our indices. I performed a social networks survey in the Contrast study to assess the value of a cohesion survey (I provide relevant details in Appendix \ref{app:Contrast}); while the methods need to be tuned and revised, this is a promising approach. A better assessment of organizational shared understanding is one of the central goals of my future work. I discuss it in greater depth in the next chapter.


\section{Theoretical considerations}

Since this dissertation proposes a theory, it is convenient to analyze whether its claims fulfill some basic requirements of theoretical work. Specifically, we are concerned with the questions of refutability, predictive power, and usefulness. This section addresses these issues.


\subsection{Refutability and predictive power}
\label{sec:Refutability}

The theory as stated in the previous chapter is open to refutation through empirical evidence. Its core is based on arguments that are difficult (but not impossible) to assess empirically, such as the claim that coordination and communication are essential problems for software development, and that they are difficult to achieve effectively. But attempts at refutation can be aimed at the logical implications of those arguments, which offer better opportunities for empirical analysis.

For instance, the theory states that project lifecycle processes and documentation are poor substitutes for practices such as radical team co-location, group-based story definition, and pair programming, where these practices can be applied. There are some empirical results that support this implication, such as the work of Teasley \emph{et al.}\ \shortcite{Teasley2002}, summarized in section \ref{sec:Teasley}. But the implication could also be shown to be empirically incorrect in some cases, and if this disagreement between theory and data cannot be explained through contextual elements, then such results would challenge the theory.

However, we would need to be careful to make a proper assessment. Studies such as the evaluation of pair programming by Arisholm \emph{et al.}\ \shortcite{Arisholm2007}, while useful for other reasons, are inappropriate as an assessment of the benefits of the pair programming practice. In that particular case, the researchers assigned pairs of programmers among strangers, for a single day, to work on code and on a domain they were unfamiliar with. Any results on the effectiveness of pair programming would be unsatisfactory because pair programming is not meant to be used in this context.

The shared understanding theory also states that, all else being equal, group cohesion leads to a greater shared understanding of the situations the organization faces, and therefore, to greater success (assessed as the satisfaction of the goals of members of the organization). It states that co-location in the same shared physical space helps to enhance cohesion (and therefore performance) and brings proximity, synchrony, proportionality, and maturity to group interactions; and that organizational growth hinders these very attributes and leads to formalization, and therefore, to a loss in relative performance.

These are testable statements, although they cannot be tested trivially. Each of them demands a careful case selection and data collection. Given the domain they deal with it is unlikely that they can be tested in a controlled environment. But they are all feasible tests, and a negative result on any of them would cast doubts on the core of the theory.

Furthermore, the theory holds predictive power: each of its implications can be phrased as a prediction for specific software organizations.\footnote{Section \ref{sec:Implications} discusses the implications of the theory extensively.} The predictions, of course, need to be tempered by the context of the organization, but to date they appropriately explain my data and that of other studies reported in the literature.


\subsection{Usefulness}

I believe that the theory of shared understanding states something important about one of the most vital activities of modern society, and therefore that it has valuable use. It reinterprets our software development experience, giving primacy to the essential difficulty of coordinating and communicating in a complex, intellectually demanding context; it provides guidelines for practitioners on methodological and technical choices; and it establishes an interdisciplinary framework for researchers to use instead of our current (and simplistic) models of coordination and communication. Section \ref{sec:Implications} describes in detail the ways in which the theory changes our conceptualization of software development work.



\section{Relationship to other current work}

The theory presented in the previous chapter provides a framework for studies that make use of the shared understanding paradigm as discussed in section \ref{sec:SharedUnderstanding}. This includes the work of Sharp and Robinson \shortcite{Sharp2004}, Teasley \emph{et al.}\ \shortcite{Teasley2002}, Chong and Hurlbutt \shortcite{Chong2007}, and Martin \emph{et al.}\ \shortcite{Martin2007}, discussed in that section. It is also relevant for work such as the report by Cherubini \emph{et al.}\ \shortcite{Cherubini2007} on the reasons and the means by which software developers use drawings, for Sim and Holt's \shortcite{Sim1998} study of the learning curves of software immigrants, and for the evaluation of the Viewpoints framework by Easterbrook \emph{et al.}\ \shortcite{Easterbrook2005}. The theory is most akin to this kind of research, and supports it.

However, the theory has links to other current work that should be discussed. First, there is the Socio-Technical Congruence community. Represented by studies such as those of Herbsleb and Grinter \shortcite{Herbsleb1999}, Cataldo \emph{et al.}\ \shortcite{Cataldo2006}, Nagappan \emph{et al.}\ \shortcite{Nagappan2008}, Kwan \emph{et al.}\ \shortcite{Kwan2009}, and Valetto \emph{et al.}\ \shortcite{Valetto2007}, socio-technical congruence researchers propose that Conway's Law should be seen as a ``best practice'' for software development: the coordination and communication networks of software developers should be congruent with the technical networks of the products they build, and organizations are deficient to the extent that they are not congruent in this sense.\footnote{I discuss one of the papers that state these criteria in section \ref{sec:Cataldo}.} Studies of socio-technical congruence rely heavily on mining software repositories of code and of electronic interactions. For instance, they analyze the networks of instant-messaging or e-mail sent and received by members of the organization, and they overlap this network with one of interdependencies of modules of the software products of the organization.

It should be clear that my proposals are linked to the socio-technical congruence community in terms of the domain of study they explore, but we address the challenges of the domain very differently. Specifically, I claim that it is a mistake to assume that coordination and communication can be mined the way socio-technical congruence researchers do without guaranteeing, via an exploration of the validity of their repositories, that such proxies are viable representations of coordination and communication events \cite{Aranda2009}. Even if these repositories are appropriate representations of the frequency of coordination and communication events, they are sometimes derived from the poorest kinds of interactions \cite{Olson2000}---that is, those that are recorded electronically---but studied as if they were the only ones that mattered. The results of socio-technical congruence would be most applicable for organizations with completly isolated individuals, strangers to everyone else, communicating exclusively through electronic means.

The theory of shared understanding, then, helps reorient socio-technical congruence studies. It emphasizes that it is important to analyze other, richer, kinds of coordination and communication data. For example, efforts to measure socio-technical congruence in an organization would be greatly improved by adding a weighted consideration of our shared understanding criteria, or even fine-grained probabilistic expectations of face-to-face interactions based on an analysis of the physical layout of the space used by the organization. It would also be improved by incorporating into the analysis knowledge of the shared experiences and history of the organization's members across years and products \cite{Aranda2007}. The actual mechanisms to perform such analyses is an interest of mine, and I plan to address it in my future work, as I describe in the next chapter.

This theory also provides a foundation and explanatory power to other works, such as that of Bird and Nagappan \shortcite{Bird2009}. Their investigation discovered that organizational distance among members of the organization working on the same module is a better predictor of software faults than their physical distance. The relevance of organizational distance is in line with our theoretical reasoning: we should expect, especially in a large organization, that individuals in different departments hold very different goals, and given that coordination consists of the development and negotiation of shared goals and plans, people that follow different plans and goals should struggle to coordinate effectively. The theory also predicts that physical distance itself would be an aceptable predictor of software faults; it simply does not state which predictor is better. Bird and Nagappan's work helps to answer this question.

Finally, the theory holds similar links to studies of tool use in software development such as those of Treude and Storey \shortcite{Treude2010}, who report that developers use dashboards and feeds to make sense of the status and activities of relatively large software projects: dashboards are used for task prioritization, while feeds are used for short-term planning. This kind of studies complement my work, focusing on an area (the development of shared understanding through the use of software tools) that I have not explored myself.
