\chapter{A Theory of Shared Understanding}
\label{chap:SharedUnd}


This chapter constitutes the main contribution of the thesis. It builds upon the literature described in Chapters 2 and 3, as well as on the case studies summarized in Chapter 4 (and discussed at greater length in the appendices), to present a theory of shared understanding for software organizations.

The theory arose from those studies indirectly. As a result of the first case study, two hypotheses seemed to compete for an explanation of the diversity of coordination and communication decisions in software organizations (see sections \ref{sec:Adaptation} and \ref{sec:CulCohesion} for a discussion of the two hypotheses). These hypotheses turned out to be inadequate to explain the diversity of successful strategies when I probed them more deeply in the Contrast study (this inadequacy is discussed in section \ref{sec:AdaptationVsCohesion}), so I explored other phenomena that could explain it. An emergent theme was the effort at both firms in the Contrast study to ``spread the knowledge'' of their situations among their members: the construct of shared understanding, with which I was already familiar, became an interesting explanation for the phenomena I observed. It also became clear, through an analysis of Saville's implementation of Extreme Programming, that many of the practices proposed by the agile movement have the same desired effect of sharing an understanding, directly or indirectly. This prompted an evaluation of the data of the other case studies under a similar light. I found that every case study provided additional and complementary findings when analyzed from the point of view of the challenges and strategies to share an understanding between members of the organization. More importantly, such findings had useful, direct implications for the field. Therefore, the theory did not emerge linearly from the data, steadily growing more elaborate with each study, but rather, after several competing efforts, and informed by the relevant literature, remained as the best explanation I could produce for the rich set of data taken as a whole. The role of the pieces of evidence cited in the rest of this chapter, then, is to illustrate, elaborate, or debate some of the points discussed in the text, not to build the main argument on their own.

The chapter is divided in three parts. The first explores some of the basic elements of the theory, including the concepts of coordination, communication, and shared understanding. The second presents the argument itself. The third explores its implications for software research and software practice.


\section{Basic Elements}

Achieving effective coordination and communication is the central problem of software development. This insight is not evident from a cursory overview of the research literature; therefore it may appear controversial at first. The controversy could arise, in part, due to a narrow understanding of the concept of coordination and a naive understanding of the concept of communication. It should then be useful to explore these concepts to realize their proper reach and relevance.

In this section I discuss our common understanding and misperceptions of the concepts of coordination and communication. I argue that coordination and communication are two linked aspects of the same problem, a problem that amplifies the essential complexities of software development and that is particularly difficult to address given the nature of our field. I finish the section by introducting Easterbrook's \shortcite{Easterbrook1994} concept of shared understanding.


\subsection{Coordination}

Etymologically, \emph{coordination} means an orderly arrangement of elements.\footnote{\emph{Com--}together, \emph{ordinatio--}arrangement.} Generally, in the context of groups of people working together, to coordinate is to determine their plans and courses of action to meet their goals. I offer a more precise definition of coordination (and communication) for our purpose in section \ref{sec:SUTheory}; for now I will only explore several relevant aspects of the concept.

For software development organizations, coordination needs to occur among all the individuals involved in their projects: the members of the software organization, of course, but also the stakeholders with which they may (or should) interact. These individuals tacitly or explicitly prepare courses of action to meet goals as varied as the delivery of quality software, the profitable sale of their software products, the creation, protection, or distribution of intellectual property, the long-term viability of the organization, and the improvement of the well-being of the members of the organization through remuneration, professional satisfaction, and a healthy and rewarding work environment. In the shorter term, they also draw courses of action for the satisfaction of goals such as fixing a bug, decreasing the ``technical debt'' of their project, and getting out of the office at a reasonable time in the evening.

We can consider every action taken by members of a software organization with the aim of agreeing, updating, negotiating, and evaluating the progress, plans or intended goals of such members (or of others within the organization) as an act of coordination. We can also distinguish, at least conceptually, between effective and ineffective acts of coordination: an effective act of coordination achieves its intended results consistently without unnecessary expenditures of the resources of the organization or its members, while an ineffective act does not.

Perhaps the reader thinks that coordination occurs only at some times during the life of a software project, or that only a few people are responsible for coordinating the activities of the organization; for instance, when high-ranking members of the organization decide on the architecture of the software their teams will build and on the structure of the teams that will build it. In fact, coordination acts are pervasive, since goal-setting and planning are routine activities in software development.\footnote{\textbf{Scientific Groups:} The one case in which coordination acts are absent is that of the lone developer building software for his or her own exclusive use. Whenever at least two people are involved in the project, coordination needs and considerations guide their activities. Several of our cases from the Scientific Groups study fall into this category: in the most elementary groups of a junior and a senior academic figure (such as a graduate student and her advisor), the software development efforts of the former are steered by the research goals and observations of the latter. Although coordination is not as intensive here as in more complex organizations, it still plays a central role in negotiating what is feasible, what is needed, and what should be addressed next. See section \ref{sec:ScientificOrgStruct} for a more detailed discussion of organizational forms and dynamics in these scientific groups. Coordination efforts were far more intense in every other case study discussed in the appendices.} Consider that feature prioritization, bug triaging, effort estimation, contract and requirements negotiation, ticket assignment, and even pair programming are coordination acts.\footnote{Coordination in pair programming has been reported by Chong and Hurlbutt \shortcite{Chong2007}; furthermore, Chong and Siino \shortcite{Chong2006} note that this coordination can happen subtly and tacitly in co-located environments: the environment of pair programmers would offer hints to potential interruptors for when would be a good time to interrupt their targets.} In all of these situations, groups of people interact to refine their goals and to shape their plans. In a broader sense, coordination occurs when managers prescribe a project lifecycle process, and when developers choose to adhere to or ignore the prescribed process. It even occurs in hiring decisions and annual human resources evaluations: with these decisions and evaluations the organization sets the tone for the kind of people and behaviour that it wishes to encourage.\footnote{\textbf{Contrast Study:} Hiring decisions are an integral part of the strategy of Saville. Its members feel that their development dynamics are so different (and better) to those of standard software organizations that they strive to preserve them as such; several interviewees mentioned the care taken to only ``let the right ones in.'' In Bespoker, annual evaluations are performed with a mentor who helps correct the course of the employee under evaluation to fit the organization and the developer's goals; mentor and mentee discuss possible projects to work on that will satisfy the organization's needs and the career growth wishes of the mentee. I did not study hiring decisions or annual performance evaluations as coordination mechanisms in my previous studies, but DeMarco and Lister \shortcite{DeMarco1987} discuss similar concerns in other organizations.} Most members of software organizations, then, are engaged in goal-setting and planning on an everyday basis, at different levels. All of them, therefore, are involved in coordination.

Such a broad concept risks trivialization: one could potentially characterize any action in a software organization as a coordination action, given that any activity can be seen as an effort to better set the organization's goals and plans. Coordination actions are indeed quite frequent in software development, and developers spend a significant amount of their working time explicitly coordinating with their peers \cite{Perry1994}. But not every action is a coordination action. Perhaps we should not consider most individual actions (such as writing code in solitary), nor group actions that have no bearing on the satisfaction of the organization's goals (such as informal and personal chit chat) as coordination actions.\footnote{Depending on context, even in these cases some coordination may be taking place. A solo coder may be commenting her code to make it easier for her teammates to understand what fragments remain to be worked with; informal watercooler conversations sometimes lead into work-related discussions\cite{Bellotti1996}.} Instead of classifying events as coordination or non-coordination actions, it is better to think of the coordination \emph{aspect} of these events, along with their other aspects (technical, economical, social, or otherwise). Members of software organizations coordinate to varying degrees throughout their work days, even when they are purportedly doing something else.

In sum, coordination is an essential aspect of collaborative software development.\footnote{\textbf{Contrast:} I logged hundreds of daily, routine instances of coordination in Bespoker and Saville. Furthermore, and in opposition to the stereotype of lone coders typing away in their cubicles, the professional interaction networks of both organizations are quite dense. At Saville, organization members interact professionally with 47\% of their peers; at Bespoker the corresponding figure is 45\%. Considering that both organizations have several major internal groups working on different projects, these figures are surprising. I did not collect network densities for the rest of the case studies, but the central role of coordination in many of them was clear through qualitative and quantitative evidence (see, for instance, table \ref{tab:MicrosoftCases} regarding the number of people and events involved in the resolution of bug cases in the Microsoft study.} It occurs continuously, sometimes explicitly and sometimes implicitly, and not always successfully.\footnote{\textbf{Microsoft:} Among other pathological coordination patterns, Microsoft employees claim that snowballing email threads occur in the resolution of 16\% of the bugs they address, ownership avoidance occurs in 28\%, and correct fixes or diagnoses of the bug are ignored in a flurry of discussion in 9\% of the bugs. Though I collected examples of unsuccessful coordination attempts in every case study, these detailed data on pathological coordination patterns were only collected for the Microsoft study.} It involves low-level and high-level decisions. It may involve negotiation or coertion, and it can happen asynchronously. It may also be notoriously difficult; I discuss its challenges later in this chapter, after exploring the topic of communication.


\subsection{Communication}

The etymological root of communication is \emph{communis} (common), and to communicate is to make information common, to share it. Communication, like coordination, is prevalent in modern software development: it is difficult to find events that do not have a communication aspect in them, as even the act of coding in solitary is, beyond the formalization of instructions for a machine to execute, an asynchronous communication with the coder's peers through the use of comprehensible coding structures and patterns, meaningful variable names, and code comments. Members of a software organization need to be constantly aware of the status of their teams, of their progress towards their goals, of the obstacles they encounter, and of potential solutions to their problems found by their teammates. No sustainable progress can be made without such awareness: the need to communicate effectively lies at the core of collaborative software development.\footnote{\textbf{Scientific Groups:} When software development is not a collaborative activity, or when it is not a priority of the group, this observation does not hold. Some interesting edge cases come from the Scientific Groups study. For those minimal teams of a graduate student and a professor, communication was rarely about progress or obstacles in software development. For cases where several researchers in isolation develop models to be hanged on to a common framework, communication is also minimal: they do not see themselves as contributing to the same project, even though their work helps build a larger software artifact. However, for those scientific groups where software development becomes a priority, and where more than one person is actively contributing to the project, communication becomes much more intense.}

However, and in contrast with coordination (which, as I discussed above, is often conceived too narrowly), the concept of communication tends to be understood too broadly in software research, to the point where we assume that all messages are evidence of communication. To be sure, any event where a message is transmitted (any face-to-face conversation, email, instant message, phone call, meeting, etc.) between people can be seen as an \emph{effort} to communicate. But we make a mistake in assuming that such events are successful acts of communication. This assumption depends, first, on the receiver of information to pay attention and parse the message, second, on the sender and the receiver to have a common system of symbols, signs, or behaviour, third, on the sender and the receiver to \emph{use} this common system and not another to encode and decode the message, and fourth, on the receiver to know and remember enough of the context of the sender to understand the message in the manner intended by the sender---that is, the receiver needs to fill in the gaps of the message with the tacit information that was not included because the sender assumed, consciously or not, that it was unnecessary for an understanding of the message. Communication involves interpretation, and since interpretation is far from trivial, communication is prone to breakdown. Considering that effective communication lies at the core of collaborative software development, this naive view of communication is a serious fundamental flaw in the work of our community.

One way to understand these pitfalls is with the contrast between the \emph{conduit metaphor} and the \emph{toolmakers' paradigm} \cite{Reddy1993} that I presented in Chapter \ref{chap:related-sw}. Reddy claims that we assume that communication \emph{flows} between people, as if through a conduit, and that this implicit metaphor manifests itself in the language we use. Thus we say: ``Try to \emph{get} your \emph{thoughts across} better,'' or ``You still haven't \emph{given me} any \emph{idea} of what you mean.'' Furthermore, Reddy argues that this metaphor is based on the idea that we can in fact \emph{capture} meaning in words or symbols, to be accessed later by the receiver of the message. ``You have to \emph{put} each \emph{concept into words} very carefully,'' for instance, or ``Insert those \emph{ideas} elsewhere \emph{in} the \emph{paragraph}.'' Reddy's point is that the conduit metaphor is so convenient and easily accessible that we simply take it as true, even though a clear headed analysis of communication concludes that it is loaded with challenges. In contrast, Reddy offers the \emph{toolmakers paradigm}, which I described in Section 2.3 and will not repeat here. Adopting the toolmakers paradigm leads into a very different conceptualization of communication:

\begin{quote}
\emph{Partial miscommunication, or divergence of readings from a single text, are not aberrations. They are tendencies inherent in the system, which can only be counteracted by continuous effort and by large amounts of verbal interaction.}
\end{quote}

Considering the relevance of effective communication in software development, counteracting this tendency to miscommunicate should be one of the most important goals of a software organization.


\subsection{Intertwined Coordination and Communication}
\label{sec:Intertwine}

The previous two sections pointed out the relevance of coordination and communication for software development, but treated both concepts in relative isolation. In practice, they are inextricably linked.

First, there cannot be coordination without some level of communication, for the simple reason that to have individuals performing harmoniously towards the satisfaction of their goals they must have communicated and agreed upon their intentions and courses of action. This communication might have been terse, and in some circumstances (especially with teammates with a long history of working together) the \emph{absence} of details in a message, or the absence of a message itself, communicates enough knowledge about a situation for the corresponding parties to perform as expected. But even in such cases the team relies on an established system of symbols, signs, or behaviours to coordinate, and therefore it relies on communication.

Second, there cannot be \emph{effective} communication without coordination, because communication without a purpose is wasteful and does not help the organization members reach their goals. Without coordination (that is, without a sense of the goals and plans of our peers), communication could easily result in broadcasting all of our activity (or a capricious selection of our activity), out of context, because we do not know who we should communicate with, or what information they actually need. This is not meant as a judgment against willfully informal or aimless communication, but as a mere statement that without a sense of our peers' goals and plans, and of the ways in which they overlap and combine with ours, we couldn't have the criteria necessary to share the knowledge that they need without overwhelming them with irrelevant information. Effective communication gives participants information that is both relevant and sufficient for the accomplishment of their goals.

Therefore, communication enables the possibility of coordination, and coordination in turn guides communication efforts so that they are effective. The two concepts feed into each other, as effective communication may lead to better coordination and viceversa, as shown in figure \ref{fig:CommCoord}. For this reason, strategies that help improve one of the concepts should also result in benefits to the other, and the two concepts should be studied in conjunction.

\begin{figure}[tb]
\centering
\includegraphics[scale=1.0]{commcoord}
\caption{\label{fig:CommCoord}Intertwined coordination and communication.}
\end{figure}


\subsection{The Centrality of the Coordination and Communication Problem}
\label{sec:Centrality}

The previous discussion should be sufficient to support the claim that coordination and communication are prevalent activities in collaborative software development. However, we can go further: an analysis of the commonly accepted problems and risks in software development projects leads us to conclude that coordination and communication are, nowadays, the central problem of software development.

The most widely known argument on the essential difficulties of software development is Brooks' ``No Silver Bullet'' essay \shortcite{Brooks1986}, in which he writes:

\begin{quote}
\emph{The essence of a software entity is a construct of interlocking concepts. [...] I believe the hard part of building software to be the specification, design, and testing of this conceptual construct, not the labor of representing it and testing the fidelity of the representation.}
\end{quote}

Thus even developing software in solitary and for personal use is fraught with difficulties. But as Brooks \shortcite{Brooks1975} himself discussed, this essential difficulty of software development, this struggle to capture the interlocking conceptual complexities of a software entity, is amplified significantly when software is developed in collaboration and for use by others. Not only is it difficult to specify the conceptual constructs that need to be eventually represented and tested, but the specification necessarily assumes some implicit knowledge that must be shared by numerous members of the development team. Not only does the design of these constructs need to fit harmoniously with the socio-technical systems in which they will be used, but several people in the design team need to learn enough about those socio-technical systems and ensure that their implementation strategy is easily accessible to people without their deeper domain expertise. Developers deal with problems and solutions so large and complex that nobody can know everything about them: the necessary information and judgment for a task often lies, at least partially, with someone else. In other words, the need to coordinate and communicate magnifies the essential difficulties of software development.

There are manifestations of this problem in many of the subdisciplines of our field, which are arguably about coordination and communication under a different guise. For instance, the entire ``requirements engineering'' literature is an effort to address the problems of communicating enough knowledge about a domain and about the implementation of a solution for that domain to a group of developers, of documenting such potential solutions reliably, and of coordinating changes to those solutions efficiently.

And while requirements errors are the most expensive errors in software projects \cite{Boehm1981}, in projects with traditional development lifecycles integration errors are just as problematic: it is in the integration phase that breakdowns in coordination and communication finally become apparent in the form of mismatching interfaces, incompatibility between modules, and inadequate testing.\footnote{\textbf{Microsoft:} Brooks stated that these problems increase significantly with the size of the development team, but it is difficult to understand the scale of the problem without analyzing it firsthand. As an example, in our Microsoft Study, the sample of ten bugs I studied included one case where 42 people coordinated to solve the problem and nearly three hundred people more received some communication about it. Two other bugs involved about two dozens of people coordinating to solve them. The single feature development case of that study uncovered the direct involvement of 45 people and the indirect involvement of 23 more in its design or implementation, and the creation of 21 documents spanning hundreds of pages, all of this for the addition of a checkbox in a widely used software product. The study also discovered the use of highly inefficient (though perhaps necessary) coordination patterns, such as the firing off of emails to hundreds of unknown recipients in the hope that one of them, somewhere, can provide some expertise in the resolution of the problem. This list of coordination patterns can be found in tables \ref{tab:MicrosoftPatterns1} and \ref{tab:MicrosoftPatterns2}. The challenge of coordinating the resolution of integration errors in the smaller organizations of my case studies was comparably far simpler.}

These requirements and integration challenges should be compared with the purely technical problems that software teams struggle with. The profession of software development continues to demand a high degree of technical sophistication, and there are many highly complex problems that reach the limits of our Computer Science knowledge. However, the great majority of our software projects take place completely or mostly within the bounds of such knowledge. For these projects technical challenges are certainly present, but the effort that they demand is overshadowed (and magnified) by the coordination and communication effort.\footnote{\textbf{Scientific Groups, Particle Physics:} Even projects that one might think are pushing the boundaries sometimes turn out to have fairly typical software development challenges. The ATLAS project probes questions at the very edge of our knowledge of the Universe, and yet the five participants of this project that I interviewed seemed most blocked by questions regarding the use and modification of the ATLAS software: how to get it to run under certain conditions, how to extract the data they need, what happens if they modify a certain piece of code. Their supervisors expect them to struggle with these questions for at least one or two years. To ease their learning process, these scientific groups resort to establishing liaisons to the headquarters of the project at CERN or to other research centres through postdoctoral fellowships or research visits: a visiting postdoctoral fellow is a source of knowledge about the intricacies of the ATLAS software. I only observed this dynamic in two cases: the ATLAS project and a medium-scale protein-interaction project.}

In sum, coordination and communication problems amplify the essential difficulties inherent in software development. Considering their prevalence, they are the central problems of our field.


\subsection{The Difficulty of the Coordination and Communication Problem}

Having established that effective coordination and communication is the central problem of software development, I will now show that it is particularly difficult to achieve due to the overwhelming amount of information that group members need to parse, the need for the development of tacit, complex, and specialized knowledge, and the exploratory nature of many software projects.

First, it should be well known that non-trivial software projects produce an overwhelming amount of information \cite{Yatani2009}.\footnote{\textbf{Microsoft:} Recall that three out of the ten cases in this study of bug fixing included more than one hundred interaction events. No comparable metrics were collected in the rest of my studies.} Group members who want to stay informed of every event in their team would need to dedicate so much time to reading the code, the emails, the bug database entries, version control logs, specifications, design documents, and other artifacts that their teammates produce that they may not have any time left to produce information of their own. Furthermore, researchers and software professionals continue to create tools to generate and transmit even more information on the grounds that it is to the advantage of the software team to have access to it.

This abundance of information translates into a scarcity of attention. Each group member makes their own decisions as to what pieces of information they will invest their time with, and these decisions are based on their own personal perspective of what are the priorities and the activities that matter for their group. Facilitating these decisions is one of the main challenges of knowledge management \cite{Alavi2001}, and it is the source of much promising work in our field \cite{Treude2009}, but our current solutions only ameliorate the problem.

The problem of coordination and communication, however, is deeper than one of a simple abundance of information to parse. Members of software organizations often need to develop tacit, complex, and specialized knowledge \cite{Schon1984}, of a kind which is unfeasible to document or operationalize.\footnote{\textbf{Contrast, Bespoker:} This was one of the principal reasons for the reluctance of Bespoker to engage in outsourcing development. The members of the organization did not think that they could successfully associate with a team from a different country and, therefore, a different context. When the organization was forced to offshore part of its development to keep a major contract, the project manager took exhaustive care to ensure that the offshore developers in India understood some details of North American policy (the domain of the application); the two firms also established a project liaison to be sitting in Bespoker's offices to relay missing pieces of tacit information as they become apparent, among other things. This example is one of many observed instances of people explicitly making an effort to overcome problems caused by the unavailability of tacit and complex knowledge; see section \ref{sec:Spreading} for more examples.} The need to develop this knowledge is evident in reports of acclimatization of newcomers to a software organization \cite{Sim1998,Begel2008},\footnote{\textbf{Contrast, Saville:} This firm has developed several strategies to speed up the acclimatization of newcomers. All software development happens in large communal rooms (more on that later), and all the current development tasks are visible for the whole group to see. Every morning, each team has a ``stand-up meeting,'' lasting somewhere between five and twenty minutes, where they discuss the events of the previous day and state what they intend to do now. Most code is developed in pairs, and the pairs are constantly shuffled so that most team members know about the structure, architecture, and ``tricks'' of all the relevant modules in the code. Organization members repeatedly refer to this process as ``spreading the knowledge.'' No other organization in my case studies had this kind of proactive effort to share tacit knowledge among its members.} but acclimatized developers still need to maintain it, and failure to do so has been found to be a major source of project falure \cite{Herbsleb1999}.

This means, in practice, that it is not enough to have access to a piece of information; one needs to understand enough of its context and of its implicit assumptions to make sense of it, and knowledge of its context and of its implicit assumptions cannot be achieved without effort and practice. A requirements document is rarely fully comprehensible on its own,\footnote{\textbf{Contrast, Bespoker:} Requirements documents do not usually seem to be intended to be comprehensible on their own, nor are they assumed to hold all important knowledge about the requirements of their projects. In the project with an offshore component, a business analyst in the team had been documenting, with significant detail, the requirements of the project; the project manager briefed the offshore team extensively on the nature of the domain of the project, on the architecture and design decisions of its finished components, and so on. Still, used to co-located development, the project manager was anxious about the success of the project and the coordination and communication demands of distributed software development, and decided to assign the India team a component of the new system that was as autonomous and disconnected from the rest as possible. In most of the cases that I studied, requirements documents (if they existed) were meant to be interpreted with assistance from their writers.} designers like to walk around the office to get a sense of the situation of their team \cite{Bellotti1996}, and Beck \shortcite{Beck1999} recommends to have a customer on-site, and the full development team sitting together, to increase the availability of implicit knowledge to the team.

Finally, to complicate things further, much software development has an exploratory nature. The problem domain and the solution may not be clear throughout most of the project, and software development becomes a creative and a discovery activity. Obstacles may arise anywhere, unpredictably, and this increases the need (and the difficulty) of establishing swift, trustworthy dynamics to communicate immediate and foreseeable problems and to coordinate to address them. In other words, the challenge that organization members face is not only one of uncertainty, but of equivocality \cite{Daft1986}: not only is there an absence of information, but there are multiple and conflicting interpretations about the situation of the organization.

Although there does not seem to be a solution that can tackle the tripartite problem of scarcity of attention, development of tacit knowledge, and equivocality, some tools or practices provide gains in some of these areas. In particular, for many of the events that matter in software development, effective coordination and communication cannot be reliably achieved through the simple transfer of data between people and artifacts.\footnote{\textbf{Microsoft:} Many of the problems and missteps we documented in the Microsoft study consisted precisely of a failure to coordinate and communicate through a simple transfer of data. At some Microsoft divisions build failures generate automatic bug reports with a wealth of data describing the failure, but such bug reports are considered by the relevant developers as merely the first set of hints to understand the problem. Typically, a discussion between several developers that try to resolve the issue ensues after such a bug report. For instance, for a particularly troubling bug, one that occasionally appeared in automated testing but could not be reproduced, and that was threatening to delay the release of a product, spurred several developers and project managers to share all the information they had about it, and to try to make sense of it. After much deduction, the problem was eventually linked to an error in the automated testing environment. The other case studies offer similar, ample evidence of the inadequacy of the simple transfer of data for the purpose of coordination and communication: the ATLAS researchers complained of such an abundance of documentation that they did not know what to pay attention to; IBM required frequent release meetings to make sense of the status of the modules of their products, beyond the information they would get in their dashboards; and Bespoker could not rely on requirements documents as its sole communication mechanism for offshore development.} A deeper, \emph{shared understanding} of the situation among its participants needs to take place. The next section discusses this concept.


\subsection{Easterbrook's Shared Understanding}

For this exposition of the concept of shared understanding I follow loosely Easterbrook's \shortcite{Easterbrook1994} unpublished manuscript on the topic, although whereas Easterbrook concludes with an interpersonal theory of shared understanding, I focus on an organizational use of the concept. Since Easterbrook's manuscript is not publicly available I will delineate some of its central points here.

Easterbrook points out that software teams must develop an understanding of the system and its context, and that this understanding is likely derived from fragmentary information because it is obtained through interaction ``with a number of disparate communities.'' He stresses that this understanding needs to be shared with the team, and that it will not be captured in technical documentation, since documentation, as I discussed earlier, ``will not include informal, anecdotal, or intangible information. (...) At the most, we can expect such documentation to provide a kind of anchor for the analysts' understanding.''

The term \emph{shared understanding} had been previously mentioned in the software literature. For instance, Walz \shortcite{Walz1993} reports on the development of shared understanding in a design team. However, as Easterbrook points out, the term is used freely and it is rarely defined. For his definition, Easterbrook uses constructs from the cognitivist study of mental models \cite{Rogers1992}, and emphasizes that individual mental models are partial, potentially inconsistent, and as superficial as they can be. As a result, ``mental models allow participants to derive a number of expectations about a situation, which they use both to explain the situation, and to make predictions. However, these expectations are often not borne out. A \emph{co-ordination breakdown}\footnote{The concept of \emph{breakdown} here is related to the breakdowns in tool use as discussed by Winograd and Flores \shortcite{Winograd1986} and Heidegger's \shortcite{Heidegger1927} \emph{ready-at-hand} concept.} is a mismatch between the expectations of one participant and the actions of another. The event that causes the breakdown may be a communication act. The mismatch might be the result of an error of communication or of perception by either party, or a difference in understanding of the situation. However, the existence of any of these conditions will not necessarily lead to breakdown.''

Using these elements, Easterbrook defines shared understanding as follows:

\begin{quote}
\emph{Two or more participants have a shared understanding of some situation, if the elements of their mental models salient to that situation are functionally equivalent. By functional equivalence, we mean that the models will provide the same explanations and the same predictions of a situation.}
\end{quote}

He explains that the relationship of shared understanding to situation is crucial (since it focalizes the concept to a meaningful and achievable scope). He uses the term \emph{situation} as ``an episode of interaction and the environment in which it takes place.'' \cite{Cody1985}. Furthermore, he differentiates between \emph{fragile} and \emph{robust} shared understanding, ``depending on whether it still holds in different situations.''

Easterbrook states that for any situation, the elements of the mental models of the participants can either be equivalent (in which case participants have a shared understanding), complementary (in which case participants have different, but not conflicting, perspectives on a situation) or conflicting (in which case they generate inconsistent expectations). Over time, the mental models and the relationship between them changes, as Figure \ref{EasterbrookSUDynamicsFig} shows. Models go through transitions of specialization and sharing, and of breakdown and harmonization; the two sets of transitions are orthogonal to each other. Easterbrook claims that breakdown dynamics, though usually seen as symptomatic of dysfunctional teams, are not necessarily negative: there are some cases in which a team may want to probe the limits or correctness of its shared understanding, and conflict may teach an organization important lessons about its systems and context. Finally, Easterbrook lists some mechanisms and techniques to bring about a shared understanding or a breakdown in groups of people in order to exploit his theory. The arguments in the remainder of this thesis are indebted to his discussion on the topic.

\begin{figure}[tb]
\centering
\includegraphics[scale=0.7]{sme-su}
\caption{\label{EasterbrookSUDynamicsFig}Easterbrook's transitions between sets of mental models.}
\end{figure}



\section{The Argument for Shared Understanding}
\label{sec:Argument}
\label{sec:SUTheory}


At this point we are ready to merge the threads of coordination, communication, and shared understanding into a cohesive structure. In this chapter I have argued that coordination and communication are central problems of software development, and that their main difficulties spawn from the overwhelming amount of information that organization members need to parse, from the need to develop tacit, complex, and specialized knowledge, and from the exploratory and creative nature of software development. For many of the events that matter in software development, effective coordination and communication cannot be reliably achieved through the simple transfer of data among people and between people and artifacts: a deeper understanding of the situations in which an organization acts, and of the strategies that the organization will deploy, must be shared by its members.

In this sense, the definitions of coordination and communication that I provided in the Introduction are unsatisfactory: they do not point to the particular difficulties of coordination and communication in software development (or, generally, in any intellectually-demanding, exploratory, collaborative task).

I propose that the concept of shared understanding, as defined in the previous section, can be profitably used to describe the coordination and communication constructs. The corresponding definitions are the following:

\begin{quote}
\emph{\textbf{Coordination} among participants in a situation consists of sharing and negotiating an understanding of their goals and plans.}
\end{quote}
 
\begin{quote}
\emph{\textbf{Communication} among participants in a situation consists of sharing an understanding of their status and context.}
\end{quote}

These definitions link the intertwined concepts of coordination and communication: both consist of the development of shared understanding among members of the organization. The distinction lies in the nature of the things that need to be shared: goals and plans for the purpose of coordination; status and context for communication. The reader should remember that this shared understanding is situation-based, as discussed in the previous section. \emph{Goals}, in this context, are what participants wish to achieve as a result of the situation. \emph{Plans} are the set of decisions and actions to be taken to address the situation. \emph{Status} consists of the current characteristics of the elements of the situation, and \emph{context} consists of the characteristics of surrounding elements that may have a bearing on the situation. In this sense, the conjunction of status and context consists of \emph{all} the information, implicit or explicit, that is accessible to the participants of the situation. The difference between status and context is that status corresponds to those elements that participants recognize to be central to the situation, while context corresponds to elements that are peripheral (and perhaps irrelevant) to the situation.

These definitions are both \emph{general} and \emph{discriminating}. That is, they are flexible enough to fit all attempts of communication and coordination phenomena as usually understood in our domain, but they give greater value to those attempts that address the challenges of coordination and communication effectively by being \emph{synchronous}, \emph{proximate}, \emph{proportionate}, and \emph{mature}, as these characteristics simplify the development of a shared understanding. Figure \ref{fig:Schema} summarizes these points, and the following paragraphs explain the four attributes of interaction.

\begin{figure}[tb]
\centering
\includegraphics[scale=1.0]{su-schema}
\caption{\label{fig:Schema}The elements of shared understanding.}
\end{figure}



\subsection{Synchrony}

Our conceptualization of shared understanding makes explicit the fact that it is situation-dependent. It does not make sense to talk about a comprehensive shared understanding among the complete mental models of several people: such understanding is theoretically impossible (it demands an exact replica of the same mental model across all the agents involved) and empirically non-demonstrable. We can talk, however, about shared understanding as it relates to a specific situation, and about the fragility or robustness of this understanding depending on whether it holds under several situations.

Although there can be some ``carry over'' from previous situations, a shared understanding needs to be developed on a situation-by-situation basis. However, in an exploratory, creative activity such as software development, many situations are unforeseeable, and in many cases the scope of the foreseeable and probable situations is too large to be manageable. In practice, we resort to modifying our plans, prospects, and behaviour in response to the characteristics of the situations we encounter \cite{Suchman1987}.

This implies that an understanding that is shared \emph{synchronously} to the situation in which it applies is more effective than an understanding about multiple potential situations shared asynchronously, in advance.\footnote{This distinction is very similar to the coordination modes discussed by Van de Ven \emph{et al.}\ \shortcite{VanDeVen1976}. They distinguish between an impersonal, a personal, and a group mode of coordination. The first involves the establishment of rules, procedures, plans, and schedules. The second and third depend on feedback to make adjustments to the plans of action; March and Simon \shortcite{March1958} talk more generally about coordination by programming and coordination by feedback. Here I make the same distinction not only for coordination, but for communication as well.} Unless the domain and the possible consequences of our actions are exhaustively understood, preparing in full our plans and documenting in full our information before the relevant situations are encountered will be either inefficient (because we wasted much effort in describing all the possible avenues of action and all the possibly relevant implicit information) or simply unsuccessful (when we failed to prepare for the unexpected situation that in fact arose). Coordination and communication, then, are most effective when they take place in synchrony to the situations they address. This applies at all levels of activity.\footnote{\textbf{Contrast, Saville:} At a high level, Saville (and to a lesser extent Bespoker), in collaboration with the customer, selects the features to work on the next iteration at the end of the current one. This allows for flexibility in the direction of their systems, and for better feedback in terms of performance, quality, and customer satisfaction. At a low level, some teams at Saville have a ``daily priorities'' mini-meeting after their stand-up meeting. Lasting no more than three minutes, it consists of people stating what they plan to work on during the day, and who will they pair with. If the team leads do not think this is the best use of their time, they discuss alternatives until they reach something suitable together. Saville's tactics were the most synchronous of all the cases I studied.}

In other words, it is easier to share an understanding about a situation as it arises than to do so \emph{a priori}. In some cases, an \emph{ad hoc} shared understanding is unfeasible, and the organization needs to depend on plans and documents drawn in advance, but this does not mean that asynchronous strategies are superior to synchronous ones when there is a choice.

To clarify the convenience of synchrony, table \ref{tab:Synchrony} describes the difference between synchronous and asynchronous shared understanding for the elements of our coordination and communication constructs. 

\begin{table}[tbp]
\caption{\label{tab:Synchrony} Synchronous and asynchronous strategies}
\centering
\footnotesize{\begin{tabular}{p{2.0cm}p{5.8cm}p{5.8cm}}
\hline \hline
\vspace{1pt} \bfseries Shared understanding of... & \vspace{1pt} \bfseries Synchronous & \vspace{1pt} \bfseries Asynchronous \\
\hline
\vspace{0.5pt} Goals & \vspace{0.5pt} Takes advantage of a greater clarity of goals brought by the particulars of the situation. \par Example: Prioritizing the stories for an iteration at the end of the previous one. & \vspace{0.5pt} Implies a commitment to a specific set of goals when these are derived from partial and possibly incorrect information. \par Example: Charting the full set of desired features of a system during a requirements phase at the beginning of the project.\\
\hline
\vspace{0.5pt} Plans & \vspace{0.5pt} Can react to uncertainties flexibly; does not need to specify most decision branches. \par Example: Determining a list of daily priorities of the team in the morning, modifiable depending on context. & \vspace{0.5pt} Plans may need to be thrown away when more information becomes available, unless a significant effort is exerted to maintain them. \par Example: Committing the organization to the release of a fully specified set of features by a given date.\\
\hline
\vspace{0.5pt} Status & \vspace{0.5pt} Only a synchronous understanding of the status of a situation enables a truthful knowledge of its current state. \par Example: Learning what other team members are currently doing to decide what one needs to do next. & \vspace{0.5pt} There is no guarantee that the status of a situation days or months ago still holds, so asynchronous status sharing is highly uncertain. \par Example: Relying, halfway through a project, on original effort estimates to determine when the project will be finished.\\
\hline
\vspace{0.5pt} Context & \vspace{0.5pt} As with status, only a synchronous understanding of the context of a situation can highlight new, important, or surprising information. \par Example: Informing bug triaging decisions with knowledge of current priorities of the customers. & \vspace{0.5pt} There is no guarantee that the context of a situation days or months ago still holds, so asynchronous context sharing is highly uncertain. \par Example: Assuming that the customer's organizational structure and priorities are the same at project completion than at project inception.\\
\hline
\end{tabular}}
\end{table}

The examples in table \ref{tab:Synchrony} make it seem as if it were foolish to ever choose asynchronous strategies over synchronous strategies. This is not my intention. Certainly, and in particular when it comes to goal and plan setting, a broad understanding of the purpose of the organization's members and of their standard courses of action is quite healthy and beneficial. I discuss this in the Maturity section (\ref{sec:Maturity}) in greater depth. The argument advanced in this section is not opposed to guiding projects and organizations. Rather, the argument favours a flexibility of choice \emph{when such a thing is feasible}, so that decisions can be made when the facts are known.

In fact, under some circumstances, software organizations have little or no choice: they are required contractually to make plans asynchronously to the situations in which the plans will be executed, or they are only given some contextual information early on and are expected to make the most of it, or have such a large team that it is impossible to manage to coordinate them on a synchronous basis. In these cases, asynchronous strategies are called for. But according to my observations, asynchronous strategies are sometimes used when their synchronous counterparts would be easily applicable. Some software organizations, on the other hand, have managed to convince their customers of the advantages of synchrony, and therefore to change their customers' demands for asynchronous mechanisms.\footnote{\textbf{Small Firms, Agilista:} This firm only takes projects from customers that agree on synchronous, proximate mechanisms, as the firm's members do not want to work under other circumstances.
\par \textbf{Contrast, Saville:} This firm has managed to convince large financial and retail organizations, which typically demand a heavy asynchronous effort, to work in a relatively synchronous fashion. Some customers still demand documentation on an iteration basis, but since iterations are fairly short Saville has access to relatively fresh information to draw its goals and plans. Agilista and Saville were the only two cases I observed where the organization took active steps towards establishing a synchronous interaction with its customers.}

Finally, the table might give the impression that synchrony is a binary attribute: either an understanding is shared the moment the situation arises, or it is not. Synchrony, however, should be assessed with greater nuance. Year-old plans and week-old plans are both technically asynchronous, but they are not equally unreliable. Customer feedback that is an hour old is far more valuable than customer feedback months ago. The synchrony attribute, then, should be seen as a continuous dimension, where closeness to the present is desirable but rarely fully attainable.


\subsection{Proximity}

Since we are interested in a domain with large amounts of tacit information, developing a shared understanding is most effective when it occurs in physical proximity to its situation. This is because the richness and the opportunities provided by physical proximity are not matched by our current (nor by our potential) tools to collaborate at a distance \cite{Olson2000}.

In other words, if the agents that need to develop a shared understanding about a situation are physically proximate to the situation and to each other, they have access to a more significant portion of the tacit or implicit information that is necessary to a proper assimilation of the situation.\footnote{\textbf{Contrast:} An intense use of proximate strategies at Saville allowed me to get a quick understanding of the status of every team within the first day of my observations. Getting to the same level of understanding at Bespoker took a considerably longer time, and depended on numerous one-on-one interviews. I did not perform similar observations for the other case studies.} Unfortunately, we deal with an industry that increasingly focuses its activities in distributed development and offshoring, and some in our community advocate shutting developers in isolation in order to help them concentrate on their technical problems \cite{DeMarco1987}. And yet, as I have mentioned before, geographical distribution causes a greater number of coordination breakdowns \cite{Herbsleb1999}, physical co-location is a viable, effective strategy to improve the efficiency of software projects \cite{Teasley2002}, and many software development practices currently in use take advantage of physical proximity to share an understanding in a quick, reliable manner. Table \ref{tab:Proximity} specifies the differences between proximate and distant efforts to coordinate and communicate.

\begin{table}[tbp]
\caption{\label{tab:Proximity} Proximate and distant strategies}
\centering
\footnotesize{\begin{tabular}{p{2.0cm}p{5.8cm}p{5.8cm}}
\hline \hline
\vspace{1pt} \bfseries Shared understanding of... & \vspace{1pt} \bfseries Proximate & \vspace{1pt} \bfseries Distant \\
\hline
\vspace{0.5pt} Goals & \vspace{0.5pt} Implicit cues about a domain and a stakeholder become apparent when participants interact with them firsthand. \par Example: Picking non-verbal hints about a stakeholder's satisfaction in a product demo. & \vspace{0.5pt} Relies on explicit information to set and modify goals, with greater potential for breakdowns. \par Example: Using textual feedback from stakeholders to assess their satisfaction.\\
\hline
\vspace{0.5pt} Plans & \vspace{0.5pt} Can make use of team co-location to make plans easily shared and available. \par Example: Using whiteboards to track the components of stories that still need to be worked on. & \vspace{0.5pt} Must rely on poorer communication mechanisms to establish and update plans \par Example: Developing project plans for an offshore site.\\
\hline
\vspace{0.5pt} Status & \vspace{0.5pt} Implicit cues about the status of one's peers become apparent with direct interaction. \par Example: Daily stand-up meetings. & \vspace{0.5pt} Relies on explicit information to learn about the status of one's peers. \par Example: Management dashboards.\\
\hline
\vspace{0.5pt} Context & \vspace{0.5pt} Co-location shares details on many implicit contextual elements otherwise inaccessible. \par Example: The ``buzz'' or concentration of a pair of programmers that lets potential interruptors know when to ask a question. & \vspace{0.5pt} Implicit contextual details are often ignored. \par Example: Making a phone call to the same programmers to ask a question, while they were focused coding.\\
\hline
\end{tabular}}
\end{table}

As with the synchrony attribute, proximity is a continuous variable. However, it is not simply the plain distance between members of the organization that we are interested in: it is a matter of access and availability. The layout of one's office increases the saliency of some implicit details about one's peers, and hides others. A team could work in an open-plan room or in the same space with cubicles to very different effects. Doors, stairwells, and elevators have a disproportionate impact on the perceived availability of one's peers \cite{Allen1977}. And full proximity, or radical co-location, is not always possible, especially with larger organizations---although some, even among the largest, find ways to maintain most of the members of a team within physical reach from each other \cite{Bird2009}.\footnote{\textbf{Microsoft:} When interviewing people in this study, I found that it was common for me to find every one of the major players in the resultion of a bug in the same building---often in the same hallway. Even when this was not the case, the Microsoft campus has an extremely efficient system of shuttles to transport its workers quickly and on-demand between buildings. Several interviewees complained about Microsoft's relatively recent drive towards offshoring, as they could not just walk to the office of the offshore developers to sort things out. The other large organization I studied, IBM, did not have a comparable strategy to ensure proximity. Teleconferences were common at IBM, even among people working in the same building and across the hall.}


\subsection{Proportionality}

The concept of proportionality applied to coordination and communication is less common than those of synchrony and proximity, and it may require some explanation. Proportionality, in this context, refers to a balance between the involvement of each agent in the situation and the situation's needs; an alignment of responsibility with authority.

Proportionate coordination consists of coordination that is performed by the people who will be primarily affected by the consequences---and most knowledgeable about the details---of the situation they face. It emphasizes shared responsibility and team ownership of the strategies used to deal with the production of their systems.\footnote{\textbf{Contrast, Saville:} I witnessed a somewhat impressive proportionate coordination event in one of the teams of Saville. The team was behind schedule with a relatively new customer, and wished to convince the customer of its development style and performance. One day the team lead requested that everyone in the room analyzed the tasks that were pending for that iteration, and called for a meeting where they would decide if they were going to make it or not. At the meeting (and in the presence of their customer representative), he explained the pressure that the team was under from the customer's side. Team members spoke for or against the possibility of finishing their tasks on time. Although some people thought that it was manageable, it became clear that most believed it would not be: they had been overrunning their ambitious estimates in the past few weeks, and everything indicated that this would happen again. It was best, they said, to bring down the customer's expectations. To my surprise the team lead did not challenge the developers' opinions, and he did not try to force them into ``working harder'' to achieve their goals. He re-stated the emerging consensus and, somewhat resigned, said that he would communicate this to the customer and try to make the best of it. He did ask for the team to focus on finishing completely a fraction of the features so that the team had enough to show for the iteration. This event was unusual; I did not observe comparable situations in any other case study.} Proportionate coordination is also the principle behind self-organizing teams \cite{Moe2009}, and it is similar to Beck's \shortcite{Beck2005} concept of Accepted Responsibility:

\begin{quote}
\emph{Responsibility cannot be assigned; it can only be accepted. If someone tries to give you responsibility, only you can decide if you are responsible or if you aren't.}
\par \emph{The [Extreme Programming] practices reflect accepted responsibility by, for example, suggesting that whoever signs up to do work also estimates it. Similarly, the person responsible for implementing a story is ultimately responsible for the design, implementation, and testing of the story.}
\par \emph{With responsibility comes authority. Misalignments distort the team's communication. When a process expert can tell me how to work, but doesn't share in that work or its consequences, authority and responsibility are misaligned. Neither of us is in an intellectual position to see or use the feedback we need to improve. There is also an emotional cost of living with misalignment.}
\end{quote}

Disproportionate coordination is performed by people unrelated to the situation under consideration. It is an imposition of a plan of action and of the goals to pursue in the situation, determined by somebody other than those involved in it (usually by someone at a higher level in the corporate hierarchy) or by a mere fraction of those involved. According to my theory, the problem (beyond a loss of agency and the corresponding emotional cost that Beck speaks of) is that disproportionate coordination is inefficient: it consists of drawing plans without proper knowledge of the situation nor proper feedback from the execution of the plan, and it consists of setting goals that benefit only a fraction of the members of the organization. When high-level coordination is disproportionate, the goals of some members of the organization may be overlooked or dismissed. Under some circumstances this may lead to the successful completion of the software project from the point of view of those doing the coordination, but the same project may have been a failure from the point of view of those organization members that did not have a say in goal-setting and planning: they may have felt cheated by the organization and may leave when the opportunity arises. This loss of talent and experience is significantly harmful to the organization \cite{DeMarco1987}.

Proportionate communication, in turn, consists of enabling and allowing all the parties involved in a situation to share whatever knowledge they consider to be relevant to the resolution of their situation. It involves an open consultation with all stakeholders, and it prioritizes the feedback from those parties most knowledgeable and more directly affected by the situation. It is the foundation of strategies such as Participatory Design \cite{Kensing1998} and viewpoints-based modeling \cite{Easterbrook2005}.

Disproportionate communication, finally, relies only on information from a fraction of sources that leads to a picture of the situation that is incomplete in important ways. It does not seem as if there are any open advocates of disproportionate communication in the software research field, as its problems are evident, although disproportions in practice remain fairly common. Disproportionate coordination, however, has many advocates: it is the essence of many Process Engineering proposals (discussed in section \ref{sec:ProcessEngineering}). One of the reasons seems to be an understanding of software organizations as rational systems \cite{Scott2007}, a paradigm that is inadequate for the explorative, self-directed work in software organizations. It is more useful to conceive of software organizations as natural-open systems---that is, to treat them as ``collectivities whose participants are pursuing multiple interests, both disparate and common, but who recognize the value of perpetuating the organization as an important resource,'' collectivities that not only interact with their environment, but that have in this interaction an essential component to the viability of their system.\footnote{Chapter 3 discusses organizations as rational, natural, and open systems.}

Table \ref{tab:Proportionality} summarizes some of these observations regarding proportionality in our context. Note that proportionality, like synchrony and proximity, is not intended to be a binary dimension.

\begin{table}[tbp]
\caption{\label{tab:Proportionality} Proportionate and disproportionate strategies}
\centering
\footnotesize{\begin{tabular}{p{2.0cm}p{5.8cm}p{5.8cm}}
\hline \hline
\vspace{1pt} \bfseries Shared understanding of... & \vspace{1pt} \bfseries Proportionate & \vspace{1pt} \bfseries Disproportionate \\
\hline
\vspace{0.5pt} Goals & \vspace{0.5pt} The shared criteria for success are the result of negotiation between all stakeholders involved. \par Example: Decision making in self-organizing teams. & \vspace{0.5pt} Criteria for success benefit some stakeholders to the detriment of others. \par Example: Aggressive scheduling, project ``death marches.''\\
\hline
\vspace{0.5pt} Plans & \vspace{0.5pt} Those with most access to information get to plan the strategies to solve the situation. \par Example: Effort estimation performed by the developers who are going to write the corresponding code. & \vspace{0.5pt} Plans are prepared by people with partial knowledge and indirect feedback. \par Example: Effort estimation performed by managers or salespersons.\\
\hline
\vspace{0.5pt} Status & \vspace{0.5pt} The status of all participants in a situation is shared, and this information is weighted accordingly. \par Example: Customer involvement on-site, with developers probing the customer to understand project requirements. & \vspace{0.5pt} Status is shared selectively based on private agendas, or some participants are ignored. \par Example: Downplaying quality assurance reports to get a release out quickly.\\
\hline
\vspace{0.5pt} Context & \vspace{0.5pt} The full context of the situation is shared and weighted accordingly. Striving for teams of generalists rather than specialists. \par Example: Selecting programming pairs based on a mix of expertise of the code in which they will work. & \vspace{0.5pt} Context is shared on a (subjective) need-to-know basis. Favoring the formation of specialists and ``information hiding'' principles in the team. \par Example: Strong personal code ownership.\\
\hline
\end{tabular}}
\end{table}


\subsection{Maturity}
\label{sec:Maturity}

If every situation in software development was unique and unrelated to all others, it would not be necessary nor convenient to evolve patterns of responses to them. However, although each situation may be distinct from all others, it shares some patterns, a degree of similarity, to other situations encountered before. With each time that an organization faces a certain kind of situation, its reactions and expectations adapt, and it develops a vocabulary and a set of assumptions whose value lies in the fact that they arose from direct need.

In terms of shared understanding, this means that as an organization evolves its behaviour to face some particular kinds of situations, the difficulty of establishing a shared understanding of those kinds of situations decreases considerably. This is partially due to the internalization of tacit knowledge \cite{Schon1984}, and partially due to the establishment of a transactive memory system \cite{Wegner1991} that minimizes the coordination and communication requirements of the participants of a situation.

Interactions mature within the organization. Thus a process or practice that has been perfected in one organization cannot be formalized and simply ``copied'' to another one and assumed to work in the same manner.\footnote{The only example of a successful transplant of mature techniques that I found was the case of Saville, discussed below. However, it was initially problematic, and demanded a significant effort from all levels of the organization.} Pattern detection and familiarity occur within each organization member's mind (although progress done in other settings may be used profitably to simplify the adoption process and to share some common pitfalls and problems). Similarly, interactions mature out of need: maturity will develop in those areas of activity that are most often exercised.\footnote{\textbf{Microsoft:} The long list of steps that new features need to go through (including performance and security audits, test plans, and more) seem to be the result of an organizational learning that is more or less proven to work, and expected by all members of the organization. Similarly, the other large organization I studied, IBM, has a well established software development process and a division in charge of fine-tuning it according to the requirements of each of its groups.}

Therefore, organizations develop patterns of coordination and communication through their everyday experience. While the patterns of successful (or surviving) organizations are not necessarily optimal for their situation, they satisfice their goals, and we can at least assume them to be moderately efficient \cite{Aranda2007}. This means that, under many situations, the advantages of switching to a promising set of coordination and communication patterns has to be weighted against the loss in maturity entailed by engaging in a new (for the organization) set of coordination and communication patterns. Ultimately, then, this is an argument against radical changes in the management of software projects. Project managers cannot simply choose a new development method for their team and expect it to work well.\footnote{\textbf{Contrast, Saville:} As I describe in Appendix \ref{app:Contrast}, Saville did not begin as an Extreme Programming firm. When two senior developers convinced management to attempt a switch to agile practices, the effort mostly failed: some of the more technical practices (such as test-driven development) took some hold, but most did not. The firm eventually tried again, with the coaching of Kent Beck, and gradually established itself as an agile firm. Among possible success factors were the fact that the firm was already used to radical co-location, Beck's enthusiasm, a match between the Agile manifesto and the values of the firm's managers, and the willingness of the firm to learn a very different software development strategy, acknowledging the risks and early inefficiencies of the switch. Saville is the only case in my studies of an organization successfully making a significant change in its development strategy.}

Table \ref{tab:Maturity} clarifies the concept of maturity as it relates to coordination and communication patterns. Clearly, of course, maturity is also intended as a continuous variable.

\begin{table}[tbp]
\caption{\label{tab:Maturity} Mature and immature strategies}
\centering
\footnotesize{\begin{tabular}{p{2.0cm}p{5.8cm}p{5.8cm}}
\hline \hline
\vspace{1pt} \bfseries Shared understanding of... & \vspace{1pt} \bfseries Mature & \vspace{1pt} \bfseries Immature \\
\hline
\vspace{0.5pt} Goals & \vspace{0.5pt} Organization members know and (mostly) agree with their goals, and they can assume they are stable. They can make decisions on the spot in accordance to the organizational goals. \par Example: Team members relying on their previous behaviour to decide whether to postpone a defective release. & \vspace{0.5pt} No safe assumptions can be made about the goals of the organization or one's peers. \par Example: A group of university acquaintances creating a start-up for reasons unknown to each other. \\
\hline
\vspace{0.5pt} Plans & \vspace{0.5pt} In commonly encountered situations, participants know who is supposed to do what, and can react accordingly. \par Example: A developer that knows how a tester will test her module can leave ``hooks'' to simplify the tester's task, and the tester can expect they will be there. & \vspace{0.5pt} Participants remain highly uncertain about their peers' behaviour, and need to prepare more explicit plans for collaboration. \par Example: A newcomer to a project can at best be expected to do minimal contributions.\\
\hline
\vspace{0.5pt} Status & \vspace{0.5pt} The organization has found ways to share relevant status information quickly and efficiently. \par Example: Informative workspaces in agile team rooms. & \vspace{0.5pt} It is not clear what status information to share, or to whom. \par Example: Snowballing threads and shotgun emails (see table \ref{tab:MicrosoftPatterns1}).\\
\hline
\vspace{0.5pt} Context & \vspace{0.5pt} The members of the organization have learned which contextual pieces of information should be shared in many common situations. \par Example: Summarizing stories in one or two sentences in a story card. & \vspace{0.5pt} As many contextual pieces of information as possible need to be stated explicitly to strive for an appropriate shared understanding. \par Example: Thick, thoroughly specified requirements documents.\\
\hline
\end{tabular}}
\end{table}


\subsection{Summary of the argument}

The definitions of coordination and communication above help us discriminate among coordination and communication events and strategies that are more or less effective based on their fitness to the demands of our domain. The participants involved in a situation need to arrive to a state of shared understanding of their goals, plans, context, and status. As long as their situations involve an overwhelming amount of information to parse, tacit knowledge, and an exploratory or creative design component, this is easier to achieve if their strategies to share their understanding are synchronous, proximate, proportionate, and mature.

From this discussion we can conclude that organizations that have values, structures, and practices which facilitate the development of this shared understanding---strategies that adhere to the attributes discussed above---will find it easier to coordinate and communicate effectively, and that this ability will translate into greater success in their projects. Figure \ref{fig:Schema}, at the beginning of this section, puts these elements together.

It is important to note, however, that \emph{success} is dependent on the shared and the individual goals of the members of the organization and cannot be evaluated in isolation from these goals. Group members may wish to build a long-lasting organization, or to achieve a maximum profit from minimal effort, or to have a friendly, stress-free work environment, or to create products that advance the state of the art of their niche, or a variety of other possibilities. Furthermore, the goals of several group members may conflict with each other; an analysis of the degree of success of an organization has to consider the satisfaction of shared goals as well as the satisfaction of the personal goals of the people that conform the organization. This means that a broad and simple quantitative analysis of organizational success is unfeasible. I discuss this and other practical implications of this theory in Chapter 6.

For purposes of clarity, I present the main argument of this theory in point-form:

\begin{itemize}
\item Achieving effective coordination and communication is the central problem of software development.

\item Effective coordination and communication are particularly difficult to achieve due to (1) an overwhelming amount of information to parse, (2) the need for the development of tacit, complex, and specialized knowledge, and (3) the exploratory and creative nature of many software projects.

\item For many of the situations that matter, effective coordination and communication cannot be reliably achieved through the simple transfer of data between people and artifacts. A shared understanding of the goals, plans, status, and context among the participants of the situation needs to take place.

\item Although reaching a state of shared understanding is not easy, several characteristics of interaction contribute to its establishment. In particular, a shared understanding is reached more easily through the synchronous, proximate, proportionate, and mature interaction of the agents involved in the situation.

\item Organizations that have values, structures, and practices which facilitate the development of this shared understanding and its related attributes find it easier to coordinate and communicate effectively, and this ability translates into greater success in software development.
\end{itemize}

The argument simplified above is more than an academic distinction of the concepts of coordination and communication. As I will demonstrate shortly, the argument has several direct implications on constructs that are commonly used in software research and practice:

\begin{itemize}
\item Project lifecycle processes and documentation fare poorly from the point of view of the shared understanding attributes (synchrony, proximity, proportionality, and maturity). Their substitutes, however, often do not scale well, so project lifecycle processes and documentation may be necessary under some circumstances.

\item Practices and tools are valuable to the extent that they foster the shared understanding attributes, and they should be assessed under these criteria.

\item The appropriate use of physical space is a key strategy to enable synchrony and proximity directly, and proportionality and maturity indirectly.

\item Organizational growth hinders the use of effective but unscalable coordination and communication mechanisms, and it leads to the inefficient formalization of processes. Purely on these considerations, growth is harmful and it should be avoided.

\item Group cohesion enables the harmonious use of efficient coordination and communication strategies.

\end{itemize}

These implications are summarized in figure \ref{fig:Schema2}. The following section supports and explains these claims in detail.

\begin{figure}[tb]
\centering
\includegraphics[scale=1.0]{su-schema2}
\caption{\label{fig:Schema2}Implications of the theory.}
\end{figure}



\section{Implications}
\label{sec:Implications}

\subsection{Project Lifecycle Processes}

One of the most common constructs in software research is that of project lifecycle processes, also known as software development methods (or methodologies) and, more simply, processes. As I mentioned in section \ref{sec:ProcessEngineering}, designing lifecycle processes and their elements is an important component of the research agenda in this field, and development methods form the structural backbone of most current Software Engineering textbooks \cite{Pressman2004,Pfleeger2001,Ghezzi2003}.

This thesis uses the following definition of a project lifecycle process:

\begin{quote}
\emph{A \textbf{project lifecycle process} is the formalization of a repeatable, comprehensive, and generic plan to develop software projects.}
\end{quote}

The plan usually covers every major aspect of the life of the project, from inception to completion and beyond. It addresses questions such as how and who (which role) is going to elicit the requirements of the project, what should the team do if the customer wants to change a requirement, when and what does the team need to estimate effort, and what are the responsibilities of each role (and therefore of each individual).

The classic example of a project lifecycle process is the Waterfall Model, in which projects are expected to flow linearly and sequentially through a number of phases. The number and name of the phases changes, but includes elements such as Analysis, Design, Code, Test, and Maintenance.\footnote{Although Pressman \shortcite{Pressman2004} claims that the Waterfall Model ``remains a reasonable approach when requirements are well understood,'' and although much software research assumes its use, among the participants of my studies it seems to be nearly universally derided as lacking in sophistication and responsiveness.} Other common lifecycle processes are the Spiral Model and the Rational Unified Process.\footnote{I observed a variety of project lifecycle processes in use at different organizations in my case studies; I also recorded several organizations that did not follow any process at all. The following list is intended to provide a general background for the discussion in this section.
\par \textbf{Small Firms:} The cases in this study followed a variety of approaches to manage their software projects. Endosymbiotic used Scrum, Agilista followed XP, Spark followed no process at all, Bespoker used what seemed to be an adaptation of the Rational Unified Process (the picture, as I report in Appendix \ref{app:Contrast}, was more complex than that), PhoneOffshore implemented a loose waterfall with plenty of feedback loops, Growing Web's projects had generally too short a duration to warrant a full-fledged lifecycle process, and Rentcraft developed its products in iterations.
\par \textbf{Scientific Groups:} None of the cases in this study adopted a specific project lifecycle process.
\par \textbf{IBM:} An elaborate, extensible, and modifiable project lifecycle process is at the core of IBM's software development. Every group is responsible for providing a certain interface to other groups; internally they are free to pursue software development as they wish, within bounds, as long as the interfaces are satisfied and the goals met. Requirements for software projects are specified and prioritized years in advance, though there is much shuffling when projects get to their development phase.
\par \textbf{Microsoft:} As with IBM, projects are planned thoroughly. Each division pursues software development somewhat differently. Within a development cycle there are several milestones, in a spiral fashion.
\par \textbf{Contrast:} As described in Appendix \ref{app:Contrast}, I chose Bespoker and Saville because of their differences in project lifecycle processes. Bespoker, according to the Small Firms study, applied the Rational Unified Process, including the creation of detailed requirements documents and UML diagrams, and a small number of development iterations. Saville, in comparison, was a follower of Extreme Programming that was also experimenting with some proposals from Lean Manufacturing. Among other things this meant no requirements documents, many relatively short iterations, and tracking user requests through the use of a backlog and story cards. In reality, the picture was not as clear cut as this description, given to me by managers in both firms, would make it out to be. Appendix \ref{app:Contrast} has more details into the real approaches to project lifecycle processes in both organizations.} In comparison, some Agile ``processes'' (XP, Scrum) tend to provide only a very basic structure to the project, and therefore do not fall under my definition of project lifecycle processes. It is best to think of them as collections of practices, which I will discuss in section \ref{sec:Practices}.

In essence, a project lifecycle process prescribes the ideal (that is, unobstructed) workflow dynamics of a software organization. As such it is an attempt to coordinate software projects. It determines the groups and roles that will act on a project at any given time, the kinds of actions that they will take, and the people that they will pass their work to. Of course, this ideal prescription is rather abstract, so that not every detail is worked out, and it tends to be put aside when the process encounters an unexpected problem \cite{Suchman1987}. In terms of our theory, a project lifecycle process prescribes an \emph{asynchronous}, \emph{distant}, and \emph{disproportionate} approach to coordination. It is asynchronous and distant because plans are prescribed in advance, without real knowledge of the situations in which they will be applied.\footnote{Assuming, of course, that the corresponding situations do not fall under a predictable routine.} It is disproportionate because it is (usually) imposed by a number of people to a different or overlapping set of people. In other words, project lifecycle processes are an attempt to coordinate in advance, at a distance, and by decree.\footnote{\textbf{IBM:} The project lifecycle process followed by IBM has channels built in for grassroots modification, and at some level this modification is encouraged by the organization's higher management; an encouragement that should be seen as an attempt at proportionality. But such modifications are not straightforward: they must be approved by a process committee, and they must still adhere to the overall interfaces demanded by the process as is. I did not observe this mechanism at work in my other case studies.} Whoever makes the decision to use a lifecycle process determines that the rest of the organization will coordinate in the manner specified by the process to the extent possible, and that they will act in such a manner to achieve the particular goals that the lifecycle process chosen is meant to achieve. When the decision is announced to the organization, an understanding of the group's goals and plans is shared to its members. However, this understanding is imposed, rather than negotiated; other organization members have little choice but to quit or comply. It should be noted that in some cases, as with the higher levels of the Capability Maturity Model \cite{Humphrey1989}, a project lifecycle process is at least intended to \emph{mature} to suit the context of the organization.

The weaknesses discussed above should not lead us to conclude that these coordination efforts are always inferior and should be avoided. There are good reasons to engage in coordination through process definition and process adherence. First, if the process that an organization follows is formalized, then the organization can share this formalization to its members, and understanding the formalization allows them to make fair assumptions about areas of the organization that they are not familiar with. As time passes, this formalization is internalized, and thus, formalization allows for organizational growth and the coordination of larger groups of people. Second, as long as the organization members stick to the plan delineated in their lifecycle process, each of them can make better predictions of the actions and decisions of their team members. The organization becomes predictable to its members and a maturity of shared understanding of goals and plans arises, decreasing the possibility of breakdowns. In other words, established processes increase the \emph{maturity} of interactions in the organization.

Scalability and predictability are important factors for collaborative work, and therefore they are significant benefits of the formalization of project lifecycles. But this formalization also brings a number of problems. Some of them are caused by the nature of software development work: exploratory, creative, and complex. Our plans, our formalizations, are necessarily deficient: we cannot capture every detail and every exception in advance. And when the plans go wrong, when breakdowns occur (as they are bound to), a formalized organization does not have an efficient mechanism to recover; its members find themselves among strangers whose roles, skills, and habits they do not understand. The ``information hiding'' principle that enables effective formalization backfires under a breakdown.\footnote{\textbf{Microsoft:} We identified several pathological coordination patterns that were triggered by some discoveries of bugs or build errors. Microsoft employees would send emails to \emph{hundreds} of people, probing for information or expertise that could help them make sense of a new error. Most of the recipients had no way to help the sender of the emails, yet they would receive dozens of follow-up emails sent between the few developers with relevant expertise. In two of our cases the solution to the bug, discovered by a knowledgeable employee, was drowned under a stack of wild guesses; the knowledgeable person, a stranger to her peers, would have to try harder to be heard above the noise. This analysis was unique to the Microsoft study, so I do not have comparable information from other organizations.}

Even when things go well, project lifecycle plans sacrifice efficiency for repeatability and generality. Preset plans do not incorporate new information or project-specific characteristics (they are asynchronous and distant); if their execution is enforced at all times the result is highly specialized individuals spending their time performing process steps that are, often, clearly unnecessary.\footnote{\textbf{Microsoft:} Besides capturing information on ten bug cases, we tracked the development of a minor feature of a Microsoft product. This feature was minuscule when compared to the product that it was a part of; the project manager responsible for it stated repeatedly that it was so small that it could as well have been classified as a bug. However, since it was recorded as a feature, it triggered the whole feature development process of the division. It was assigned a software developer, a project manager, and a tester. It was also assigned, as secondary roles, a development owner, a user interface owner, a product planner, a test architecture reviewer, a security contact reviewer, three development reviewers, a technical writer, and contacts in other products, among other roles. It involved the creation of a summary specification, two functional specifications, two development design specifications, two test design specifications, two security risk assessments (all of these for two different milestones), a threat model document, a demo script document, legacy code removal tools, monitoring tools, and several hundreds of emails. Again, this analysis was unique to the Microsoft study; I do not have comparable information from other organizations.}

Furthermore, as I have discussed in section \ref{sec:ProcessEngineering}, a process-based approach to software development makes some questionable assumptions. It assumes that software development is a mechanistic activity with little need for discovery, design, creativity and exploration, and it assumes that the human element can be abstracted away from software research, an assumption taken to its most basic and alienating formulation by Osterweil's \shortcite{Osterweil1987} phrasing, ``software processes are software too.''

Most project lifecycle processes, therefore, are efforts to preestablish the plans, goals, and structures of an organization. Given the necessarily exploratory nature of software development, the uncertainties of the requirements, of the domain, and of the behaviour of project stakeholders and organization members, as well as the inefficiencies imposed by the push for repeatability and generality, they are far from an optimal solution.

As we will see, there are usually simpler, more adequate, and more informal solutions to the problem of effective coordination. However, these other solutions have dubious scalability. The one great advantage of a project lifecycle process approach is that it builds upon the natural inclination of organizations to formalize as they grow \cite{Blau1971,Haveman1993}. Therefore, if the members of an organization want to tackle projects of a great size, they must ensure their organization is large enough, and if it is not they must impose a level of process formalization on themselves as they grow. The difficulty resides in figuring the extent to which a formalization is made necessary by organizational size and structure, instead of misguidedly prescribed under the assumption that formalization leads to a more efficient coordination.



\subsection{Documentation}

Documentation, in the software development field, is tightly connected to project lifecycle processes: the release of documentation is often used to mark the progress of a project from a phase to the next, and the main building block of several project lifecycle processes is a document of some sort.

This thesis uses the following definition of documentation:

\begin{quote}
\emph{\textbf{Documentation} consists of text- or image-based artifacts created with the tripartite purpose of recording, communicating, and becoming enduring references for a piece of information relevant to a software project.}
\end{quote}

Most, and in some cases all, of the artifacts produced in software development projects are text- or image-based, but the previous definition is not meant to encompass all of them. Instead, it focuses on those that are created for the three reasons mentioned: to provide a \emph{record} of some project-relevant information, to attempt to \emph{communicate} said information through the sharing of the artifact, and to become a \emph{reference} for future activities in the project. Requirements documents, design documents, test plans, class diagrams, and sequence diagrams are examples of documentation using this definition, but code, emails, informal diagrams drawn on whiteboards, and story cards are not.\footnote{Some project artifacts lie in the borders of this definition. For instance, most mailing lists messages in open-source projects are not documentation, but a few may be written with the specific goals stated in the definition and are used as references for latter discussions in the mailing lists.}

The reputation of documentation-heavy approaches has suffered in recent years, and many software organizations of all kinds and sizes now advertise that they are ``agile'' and that they work with as little documentation as possible.\footnote{Recall that the Agile Manifesto signatories state that they value \emph{``working software over comprehensive documentation.''}} However, according to my observations, documentation is still heavily used in many software organizations, and even those most committed to agile principles resort to the use of documentation for a variety of reasons.\footnote{\textbf{Contrast, Saville:} This organization is strongly committed to the Agile Manifesto and to Extreme Programming in particular. However, all of its groups rely on documentation of one kind or another. Some documents are produced for contract negotiation, when necessary, and developers are sheltered from them to the extent possible. Other documents, such as ``wireframes'' (descriptions of the look and basic functionality of a screen), are widely used to give developers and customers an idea of the expected characteristics of the product. With the exception of the scientific groups, the other organizations I studied had an even greater reliance on some kinds of documents than Saville.} In particular, it seems that documentation is often present out of a need to establish a body of knowledge relevant to a project and to satisfy the demands of some customers, as a ``deliverable.''

From the perspective of the Shared Understanding theory, however, documentation is to communication what project lifecycle processes are to coordination. Documentation is a mechanism that attempts to communicate and establish a body of knowledge on a potentially large scale, to be used in a variety of situations. It is an attempt to reify the shared understanding of the team, so that the important pieces of information that the team members need to be aware of, and whose understanding they need to share, are captured in documents.

However, we know that documentation, generally speaking, cannot fully meet these goals, and in many projects it does a very poor job at them. I have discussed the issues with software documents before: first, they go stale quickly, since much of the information available when they are created becomes obsolete shortly afterwards; as reported by Lethbridge \emph{et al.}\ \shortcite{Lethbridge2003}, software developers tend to fail to update documentation.\footnote{\textbf{Contrast, Bespoker:} This is also the case for the teams at Bespoker that rely on documentation more intensely. Documents are produced on the early stages of a milestone or project, and they are not usually updated when their situation changes. However, this is not always the case: at Microsoft, feature development documents normally go through at least one revision in the course of their development.} Second, the people that should read the documents often do not read them \cite{Segal2005}; worse still, the creators of the documents assume that a silence on behalf of the supposed readers implies acceptance of the contents, not dread at the thought of ploughing through their thickness.\footnote{I discuss Lethbridge \emph{et al.}\ and Segal's studies in sections \ref{sec:Lethbridge} and \ref{sec:Segal} respectively.} And third, documentation cannot capture all of the necessary information relevant to a software team, since much of this information is tacit and needs to be learned through other mechanisms \cite{Schon1984}.\footnote{\textbf{Contrast:} This was the case both at Bespoker and Saville. In no case was the document itself sufficient as the only nor as the main tool for communication. Similarly, in my other studies, I found no major documents that were written with the intention of being a stand-alone communication artifact.}

Using the terms of our theory, documentation attempts to establish a shared understanding of the information relevant to software development situations \emph{asynchronously}, \emph{at a distance}, and \emph{disproportionately}. Its contents are often incorrect, incomplete, or superfluous to the situation at hand. For some purposes, this strategy may still be the best available alternative, and to some degree this appears to be the case at every project I have studied so far. The difficulty lies in determining when some documentation is necessary, and when is it inefficient and the information it intends to convey is better shared through some other mechanism. This is an important decision, considering the fact that the effort to create documentation is not trivial, and should not be thrown to waste.



\subsection{Practices}
\label{sec:Practices}

We can define a software practice as follows:

\begin{quote}
\emph{\textbf{Practices} are contained, repeatable, and transferable techniques used to improve some aspect of the performance of a software organization that is pertinent to the creation of its products.}
\end{quote}

It is possible to string together a set of complementary practices and to call the result a ``development process'' or ``method.'' Models like the CMM are supported by such sets of practices; the recent SEMAT initiative takes this position \cite{Jacobson2009}; and Extreme Programming is more akin to a set of practices than to a proper project lifecycle process. However, although they may synergize with others, software practices themselves are independent. Practices are mechanisms to attack a known software development problem, or to gain some generally useful benefit. They also give software organizations some low-level predictability, in the sense that its members know what to expect of their peers in commonly occurring situations.

Examples of software practices abound; they are popular constructs of our field, just as processes and documentation. For instance, \emph{code review} is a relatively well-researched practice to improve the quality of code; \emph{daily stand-up meetings} are used to provide status updates among team members and are a common occurrence of agile methods proposals; and \emph{Delphi estimations} are proposed to improve upon the individual efforts of software estimators by having them compare and iterate on their calculations.

Independently of their technical merits, however, these practices can and should be evaluated with respect to their consequences on establishing a robust shared understanding on software development organizations. A more detailed exploration of the above examples of software practices might make this emphasis on the development of shared understanding clearer.

First, let us consider \emph{code reviews}, which are prescribed mainly for their effect on software quality: they have been found to lead to greater error detection rates than traditional testing, at a lower cost \cite{Fagan1986}. There are many different kinds of code reviews, and some of them allow for very flexible steps and criteria, but the basic element of a code review is that a software developer submits a piece of code to a number of her peers, and they have the responsibility of analyzing the soundness of the code and of its underlying strategies, to spot defects and to provide recommendations for improvement. Some code reviews are performed face-to-face, some through software platforms. The number of reviewers varies; typically it goes from one to four, but larger groups are possible. Some organizations enforce the constraint that \emph{every} piece of code that enters their main repository has to pass a review; others only perform reviews selectively or upon request.

Proponents of code reviews argue that the technique effectively provides expert, or at least competent, attention and advice to the code produced by the organization, and that this attention uncovers logic errors and misunderstandings of the requirements that would be more difficult to detect through other software quality strategies \cite{Shull2002}. However, there are two other significant advantages to code reviews: they enable the \emph{reviewers} to learn about areas of the project that they might not otherwise explore, and they enable the \emph{group}, both authors and reviewers, to develop and enforce coding norms and styles.

To provide useful feedback, a reviewer needs to understand the purpose, architecture, and logic of the piece of code under review; once the review is over the author of the code leaves with a list of errors and the reviewer leaves with a better understanding of code created by someone else in the organization. If code reviews are widespread in the organization, one of their side effects is the build-up of group knowledge about all aspects of the code they work with. Effectively, reviewers emerge with a better understanding of the status and context of the code. Later on, if the reviewers need to modify or take ownership of any particular piece of code, they will know where to look for it and they will have an intuition of how it works. Traditional testing does not offer a similar benefit.

Additionally, a code review allows the whole team to interact more intensely, while focusing on the topic of code quality. They are now able to learn from each others' expertise, and if they want to pass inspections with minimal changes, they learn to write code in a way that adjusts to the team's style, idioms, and expectations. Over time, these interactions should lead to more mature coding norms and styles; Fagan \shortcite{Fagan1986} reports that developers who participate in inspections are less prone to introduce defects in their future work. Again, traditional testing offers nothing of the kind.

These are two instances of a practice leading to the development of a robust shared understanding in the organization that uses it. Although there is yet no empirical evidence of the impact of these factors in comparison to the direct impact in software quality, the mere observation that code inspections have these ``side effects'' leads to a reevaluation of the corresponding literature. For instance, Cohen \shortcite{Cohen2006} finds that increasing the number of reviewers in a code inspection quickly leads to diminishing returns from a defect detection point of view: the optimal number of reviewers is one. Similarly, Johnson and Tjahjono \shortcite{Johnson1998} find that code review meetings are not cost-effective, and Porter and Votta \shortcite{Porter1997} conclude that effort is driven primarily by the number of the reviewers participating in the inspection. However, from a shared understanding perspective a single reviewer is far from optimal, as the opportunities to establish a group culture and a group-wide understanding of as many pieces of the code as possible decrease significantly.\footnote{\textbf{Microsoft:} This was the case for one of the bug fixes I studied at Microsoft. One group had a policy to only accept code in their repository if it was reviewed by at least one person. Although in the case I analyzed this one-person review was reasonable (the fix involved importing code that solved the problem from a product built previously by the same group when they were working in another firm, one that was acquired by Microsoft along with its intellectual property, and everyone in the group were familiar with this code), in other cases a single reviewer would mean that most people would not be aware of important changes to the code. I did not observe cases of code reviews in my other studies.} To my knowledge there are yet no studies comparing the direct gains of decreasing the number of reviewers to maximize the ratio of defects-found-to-effort-spent against the indirect losses caused by a greater group ignorance of the work performed by peers and of their norms and expectations.

\emph{Daily stand-up meetings} are more obviously linked to the development of shared understanding: the team gets together and discusses the problems it found the day before and the plans for the day; evidently it is a coordination and communication activity, and it is prescribed for this reason \cite{Schwaber2001}. The one problem to keep in mind, however, is that the rote execution of the practice may not bring any of its intended benefits.\footnote{\textbf{Contrast, Saville:} In Saville there were daily stand-up meetings in every development team, and some of them were committed to the practice in letter and in spirit. However, several teams seemed to be executing the practice out of habit and of the expectation from team leaders that this is something to be done at this organization (in fact, high-ranking members of the organization believe that, though each team is relatively autonomous and free to choose its practices, there is the expectation that all teams have a daily stand-up meeting, and it would be an attack on the company's culture to do otherwise). In those less-than-enthusiastic teams, people would get together at a regular time, form a circle, and then, for the most part, have everyone ``pass'' on the opportunity to share yesterday's developments or the day's plans. There did not seem to be any direct or indirect benefit from such a half-hearted execution of the practice. I did not observe daily stand-up meetings in my other case studies.}

\emph{Delphi estimations}, finally, are meant to increase the accuracy of software estimators. This practice is not exclusive of software development; Boehm \shortcite{Boehm1981} popularized it in our field as follows: a number of experts are given a specification, they meet to discuss issues related to the specification, they estimate the effort to implement the specification separately and anonymously, a coordinator distributes a summary of the estimates, and the estimators meet again, discuss the divergences in the estimates, and prepare another round of estimation. The process is repeated until a consensus begins to arise.\footnote{\textbf{Contrast, Saville:} All user stories are estimated with an informal variant of the Delphi method. After a knowledgeable person shares the details of the user story to a group of three to five developers, they each give an estimate of the effort needed to finish each piece of the user story. The mechanism changes from team to team, but it usually involves everyone sticking out a number of fingers of their hands, representing the number of hours or ``story points'' required for that portion of the story. If there are notable differences in their estimates, they discuss their rationale until they come to a consensus. In my observations, this use of Delphi estimations was also unique to Saville: I did not record similar events at the other organizations I studied.}

By providing feedback to experts and the ability to discuss their perceptions of the specification among them, the Delphi method enables the synchronous, proximate, and proportionate development of shared understanding among them: their interaction leads them to a better grasp of the issues concerning the specification they are supposed to estimate, and differences in understanding provoke early and evident breakdowns and corresponding harmonization processes. As a result, the Delphi estimation method, independently of its advantages purely as an estimation technique, is at least in principle a valuable software practice from the point of view of our theory.

Given the variety of practices and of their motivations, it is not possible to claim that all of them help or hinder the establishment of a robust shared understanding. Some practices foster synchronous, proximal, proportionate, or mature dynamics, some do not. My claim here is that evaluating them with these criteria will give us a better sense of their worth.

In summary, the argument is that an organization can advance significantly on sharing an understanding through the judicious use of practices and without a larger and more restrictive project lifecycle process, \emph{as long as the practices can scale} to the number of participants that need to be kept involved in each situation. For the glaring problem of many practices in the literature is that they can only be executed by teams of modest sizes. Only the participating reviewers and authors gain any shared understanding benefits from a code review; only the participating attendants to a stand-up meeting gain any understanding from it; only the experts in a Delphi estimation gain a shared understanding of the specification. A large organization can ensure the execution of these practices in its sub-organizations, but any benefits gained from them will be as localized as the execution of the practices. Thus we see the need to formalize a software organization's processes as it grows: the practices that can sustain the development of shared understanding when the organization is small cannot sustain it as it grows.


\subsubsection{The Case of Extreme Programming}
\label{sec:Extreme}

Exploring the Extreme Programming proposal under this light is a useful exercise. There are two seminal books on Extreme Programming: the original work by Beck \shortcite{Beck1999} and his revision in a significantly modified second edition \cite{Beck2005}. As the second edition is more mature and has a greater clarity in the purpose of the prescriptions of Extreme Programming I use it as the focus of my discussion here.

For a proposal on software development techniques, Beck's Extreme Programming is an odd case. It emphasizes a perspective on organizational and personal values, on the humanity of software development, on communication, and on professional commitment to a work well done. One of its main points is that software development is much unlike assembly-line work; that it is a professional, almost artisanal pursuit, and that this is the essential insight of responsible software practice and needs to be taken to its extreme consequences.

Beck proposes a set of practices, but repeatedly claims that these practices will only work if the organization that executes them adheres to the organizational values that the XP framework upholds.\footnote{The values are Communication, Simplicity, Feedback, Courage, and Respect.} Linking these values to the practices are a number of principles, intermediate goals of the organization that are supposed to provide guidance to its members when it is not clear which practice to use or drop, or which decision to take.\footnote{The principles are Humanity, Economics, Mutual benefit, Self-similarity, Improvement, Diversity, Reflection, Flow, Opportunity, Redundancy, Failure, Quality, and ``Baby Steps.''} Robinson and Sharp \shortcite{Robinson2005} make a similar point, linking practices to values and explaining that what is important for an organization is to meet and uphold its values; the practices are simply instructions that work under some conditions to help the organization reach this goal.

From our point of view, what is striking is how much the practices of XP directly foster a development of shared understanding in a software organization; an effect I was able to observe firsthand at Saville in the Contrast study. The following is a brief description of the XP practices and their relationship to the development of shared understanding:

\begin{itemize}
\item \textbf{Sit together.} XP encourages radical team co-location \cite{Teasley2002}; arguing that having the full team sitting together enables teammates to develop a more robust group cohesion and awareness of the status, progress, and problems of each team member.\footnote{\textbf{Contrast, Saville:} All software development happens in team rooms with the same spatial layout: one large table in the centre with computers on its sides, all walls covered with whiteboards. People working in these rooms do not have a desk of their own; any personal belongings they want to have accessible during work hours are kept in personal lockers. In some teams people have eased into some spaces that are more or less their own, even though they are nominally shared; in other teams each individual shuffles around in different seats, sometimes three or four different seats in a single day. As a consequence, the status of the projects are immediately accessible to everyone. Customer demos take place in the same room, and when possible, a customer representative sits with the team throughout the duration of the whole project. Everyone knows if someone is sick or has a family emergency. Some employees are uncomfortable with this lack of privacy (hardly anyone checks their e-mail or browses websites during work hours), but most grow used to this and claim that it leads to stronger bonds with their peers. In my own experience, I was able to understand the context and status of their projects within the first day of sitting with the team---reaching the same state at Bespoker took a week and a half, and a number of one-on-one interviews. At other organizations, such as Microsoft and IBM, interviews were one of the few mechanisms by which I could reach a similar understanding of their projects.}

\item \textbf{Whole team.} Not only does XP propose that the full team should sit together, it considers as members of the team people that are usually relegated to the periphery of software development work: customers, managers, analysts, testers, etc. According to XP, all of these stakeholders should be immediately available to their peers, to the extent possible, so that as much of the knowledge necessary for the development of the software is spread among the team. None of the roles in the team is necessarily taken by one person; ideally, the best teams have no specialists.\footnote{\textbf{Contrast, Saville:} Except for administrative staff and the top tier of managers, everybody sits in the common team rooms. This includes customer representatives in two of the three divisions of Saville. Additionally, there seems to be an institutionalized aversion for specialization. People in all divisions spoke at several times of ``spreading the knowledge around,'' and one of the criteria to pair programmers was how much would one of the paired programmers learn about an area of the project she was not familiar with.
\par In one case, however, a developer told me that because of some carelessness he ended up being the only one in the organization that knew how to operate and modify a large-scale automated test suite. He explicitly said that he wanted to fix this, as the organization is opposed to ``silos.'' Among my cases, Saville's proactive push away from specialization was unique.}

\item \textbf{Informative workspace.} Given that the whole team is radically collocated, XP proposes to make the best use possible of its physical workspace through heavy use of whiteboards, story cards, and other props. These sensorial cues provide easily accessible information to the whole team \cite{Olson2000}, letting them know of the progress of their peers and of pieces of knowledge that are important to many of them.\footnote{\textbf{Contrast, Saville:} All teams followed the Informative workspace practice, and they provided me, visiting customers, managers, and developers, with numerous hints of the current state of the projects. The workspace was once specifically addressed in a group meeting. A manager stated that the fact that there were so many user stories mapped out in the whiteboards at various stages of completion meant that the team was spreading too much: they needed to focus on closing some of those stories as quickly as possible and free up the space. No other organization in my studies took advantage of their workspace in this manner.}

\item \textbf{Energized work and Slack.} Creative, productive work cannot be sustained over long periods for more than about 40 hours per week, nor under overly stressful conditions. These practices do not seem to have a direct impact on the development of shared understanding.\footnote{\textbf{Contrast, Saville:} They may, however, have some indirect benefits. At Saville, slack is encouraged, and it is normal to see people playing table tennis at all working hours and lingering in the lunch room while they play cards. This may help them establish and reinforce bonds with their peers, improving their cohesion, and go back to do focused work (and only focused work) in the team rooms. Other organization in my case studies, such as Bespoker and Microsoft, had similar approaches to slack and energized work.}

\item \textbf{Pair programming.} XP proposes that all production code should be developed in pairs: two people sitting in front of a single computer. Although the constant face-to-face interaction demanded by this practice causes some visceral reactions among solitary developers, and although pair programming has not been shown to bring direct productivity gains to the development team \cite{Arisholm2007}, the shared-understanding rationale to introduce pair programming to an organization is that much of the knowledge about every piece of code is shared by at least two members of the software organization.\footnote{\textbf{Contrast, Saville:} In several occasions, as mentioned above, developers would pair with the explicit goal of ``spreading the knowledge'' about a piece of code that a member of the pair was not familiar with. I documented no cases of pair programming in the rest of my case studies.}

\item \textbf{Stories.} Instead of capturing requirements in specification documents, XP uses the concept of ``stories'' and ``story cards;'' each relevant piece of functionality is captured in one or two relatively simple sentences written from the point of view of the customer. Stories are discarded once the corresponding functionality is implemented. This approach makes it far more likely that requirements will actually be read, known, and shared by the team and the customers, without introducing the overhead of writing and reading requirements documents.\footnote{\textbf{Contrast, Saville:} Furthermore, in most teams the stories are described, elaborated, and estimated by a team of four to six developers, at least one of whom will probably be involved in its development. I documented no cases of story definitions or of the use of story cards in the rest of my case studies.}

\item \textbf{Week cycle and quarterly cycle.} The actual length of the cycles varies depending on the context of the organization adopting XP and its customers, but in general XP projects progress with a short (1-3 weeks) and a long (2-6 months) iteration cycle. The shorter cycle provides the team immediate feedback on its progress and obstacles; the longer cycle gives the team and its customers an opportunity to take stock, reprioritize, and plan for the next iteration.

\item \textbf{Ten minute build, continuous integration, test-first programming, and incremental design.} These four practices are proposed with technical goals in mind, but they also have potential shared understanding benefits by simplifying the complexity of the build process (in the case of the ten minute build); providing immediate feedback on newly-created integration problems (continuous integration); allowing for the exploration of the requirements implicit in a story card by the creation of tests that, once the code passes them, will completely satisfy the story (test-first programming); and ensuring that the team is not committed to a design created early on, when the understanding of the domain is still probably low (incremental design).
\end{itemize}

In sum, an analysis of these practices and my evidence from the Saville case study show that one of the main goals of Extreme Programming is to enable the development of shared understanding in a software organization, explicitly in some cases and implicitly in others. Several practices directly aim to create an environment where the people involved in a situation can coordinate and communicate synchronously, proximally, proportionally, and maturely. To my knowledge this is the only software development proposal designed to address coordination and communication concerns so aggressively.

This analysis also shows that an organization that applies Extreme Programming both in letter and in spirit is a substantially different organization from the average software house. It works with different values, assumptions, and goals---it is a different organizational form \cite{Stinchcombe1965}. This point is confused both in the research and the trade literature by the legion of firms that claim to do agile development, or Extreme Programming, but that are far from committed to its philosophy and its organizational form.


\subsection{Tools}

The studies I reported in Chapter \ref{chap:Methods} did not have a tool development or tool evaluation component, so the following discussion is not based on my own empirical data, but on the reports from other researchers in the community. Beyond a short discussion on tool-enhanced coordination and communication, and pointers to the most promising research in the area, I have little to offer in this topic. However, at their core, tools have the same essential goals as practices, and we can use the same analytical principles in their study and design.

Software tools can be defined as follows:

\begin{quote}
\emph{\textbf{Software development tools} are electronic artifacts used to improve some aspect of the performance of a software organization that is pertinent to the creation of its products.}
\end{quote}

Tools, like practices, can be analyzed and evaluated from the perspective of the extent to which they foster or hinder the development of shared understanding in a software organization: whether they help members of the organization work synchronously, proximally, proportionally, and maturely. However, we find that many tools are built for developers working in solitary, and portraying a debugger or a compiler as shared understanding tools is inappropriate. Other tools are primarily used to coordinate or to communicate in a group: e-mail and instant messaging clients, portals, version control repositories, etc. Their use is so common among software (and other) organizations that advocating their use is not productive anymore.

There is a third kind of tools: those that are built for the purpose of coordination or communication, or that have some indirect impact on these goals, but whose use is not widespread, as they are still prototypes or unstable versions of potentially useful products. An example of this kind of tools, and arguably one that has already made the jump to widespread use, is \emph{Mylyn} \cite{Kersten2005}, which provides a task management interface on top of the Eclipse IDE, and which connects to commonly used repositories for tasks and bugs (Bugzilla, Trac, and JIRA). Other notable tools with a strong emphasis on coordination and communication are IBM's \emph{Jazz} \cite{Frost2007}, which emphasizes providing an awareness of every developer's activities and incorporates social tagging; Sarma's \emph{Tesseract} \cite{Sarma2009}, which attempts to reduce the problems of distributed software development through a dashboard with a geography- and activity-based set of panels; and Microsoft Research's \emph{Code Canvas} \cite{DeLine2010} and \emph{Codebook} \cite{Begel2010}, which respectively take advantage of our spatial awareness and of the socio-technical connections of the artifacts software developers use in order to improve their efficiency and performance.\footnote{\emph{Code Canvas}'s primary goal is not to simplify coordination or communication, but to provide a better sense of the interconnections between pieces of code and related documentation through a zooming mechanism. However, it includes some features for collaboration, so that people can ``enter'' the canvas of others, understand what they are currently working on, and leave artifacts prominently visible in the canvas for them to explore when they have the time.}

The challenge for several of these tools is to be able to filter out information that is irrelevant to their users in order to provide only what matters for the situation they currently face. The fact that we can build tools that give more and more information to members of software organizations does not mean that they will find it useful, and the poor speed with which some of these tools are adopted (and their abandonment after a trial period) suggests that the members of software organizations do not necessarily appreciate the wealth of data that these tools present to them. Distilling the essence of the questions that members of software organizations truly ask themselves \cite{Ko2007}, and then designing a tool that easily and effortlessly lets them find the answer to those questions, will probably lead to the greater advances in this area.


\subsection{Physical Space}

Much of the recent work on coordination and communication in software organizations has focused on overcoming the problems of distributed software development The push for offshoring development has made this kind of arrangement increasingly popular, even though it is known to be detrimental to the coordination and communication abilities of software teams \cite{Herbsleb1999}.

Less thought has been given to physical space layouts for teams working fully or mostly on the same site. Intuitively, we know that space and the distance and accessibility between members of a software team are factors that set the tone for their projects. Arrangements such as those of cubicle farms, or shared work rooms  encourage some kinds of interactions and disable others, although there still does not seem to be a consensus on optimal office space layouts for software development.

A popular argument claims that software organizations are most effective when they assign separate offices to each of their developers. The theoretical reason is that, since software development is cognitively complex and demanding, developers need to concentrate completely in their tasks, entering into a state of deep concentration named \emph{flow} \cite{Csikszentmihalyi1990}, an experience of full immersion, of harmony between one's actions, skills, and goals.  Since flow is both fragile and extremely important for successful creative activities, the argument goes, it needs to be nurtured in the organization by minimizing distractions. If developers are constantly being distracted at their workspace (by conversations, telephones, or the unpleasantness of smelling and listening to their peers' having lunch) they will never get anything done---and they will notice their failure, so that they will not only achieve nothing, they will become demoralized, leading to further failures in the future. Unfortunately, such distractions in co-located settings seem to be commonplace, and workflow is extremely fragmented \cite{Ko2007}.

The result of applying this argument to the design of office space is to maximize the ability of developers to isolate themselves if needed, under the reasoning that isolation leads to less interruptions and deeper concentration, which should lead to greater efficiency and product quality. Such an office space would provide every developer with a private office, even if it is relatively small, with a door that closes and a phone that can be silenced. Developers in this setting should not be expected to be online and available constantly throughout working hours, and the organization has to give them enough leeway to deal with their interruptions on their own time. When team interaction is necessary, developers should be able to use shared spaces, such as meeting rooms, and they should also have access to recreational space to socialize and recharge for their next bouts of concentration.

Proponents for this isolation often point to the popular book \emph{Peopleware} \cite{DeMarco1987}. Among other things, the book describes a competition among software developers implementing ``a series of benchmark coding and testing tasks in minimal time and with minimal defects.'' Participants record their time spent on a time log, and after they declare they are finished their products are subjected to a standard acceptance test. Developers work ``in their own work areas during normal work hours using the same languages, tools, terminals, and computers that they use for any other project.'' DeMarco and Lister found a considerable difference between competing individuals: the best participants outperformed the worst by a 10:1 ratio; the best one was 2.5 times better than the median; the better-than-median half outdid the worst-than-median half by a factor of 2. The differences could not be explained by the programming language, years of experience, salary, or number of defects submitted. The only strong predicting factor was where the participants worked: high performance competitors often came from the same companies, and their companies had better environmental factors than those of low performance competitors. Specifically, the better performers had more individual workspace, and their workspace was more quiet, private, and free of interruptions than that of the underperformers. DeMarco and Lister accept that this is not evidence of causality, merely of correlation, but claim that from a business perspective this should not matter: either a better workplace helps people perform better, or the people that perform better gravitate toward organizations that provide a better performance; the result of a good workplace is advantageous for these organizations no matter the rationale.

However, there is an important challenge to these results. DeMarco and Lister studied people working on a task \emph{individually}. To do well, participants had to work exclusively on their own to solve their problem in the best way possible. But in most cases software is not developed this way, as I discussed in section \ref{sec:Centrality}. Developers are part of a team, and the product of their individual work has to interact with that of many others; and they get and provide help to their peers. The coordination and communication demands that these teams face force us to consider alternatives to the maximal-isolation office layout derived from \emph{Peopleware}, under the assumption that an emphasis on coordination may be more important than an emphasis on concentration.

In fact, there are also theoretical reasons to emphasize coordination abilities. First of all, Csikszentmihalyi's theory of flow does not claim that flow happens exclusively in isolation---this is a misreading of the theory, which actually states that harmonious teamwork is one of the most accessible mechanisms to get into flow. Emphasizing coordination also brings other benefits. For instance, it enables the formation of the \emph{transactive memory systems} that I discussed in section \ref{sec:Transactive} \cite{Wegner1991,Hollingshead2000}.

Proximity also enables the use of richer communication channels: according to Olson and Olson, despite all our current technology for remote collaboration, face-to-face interaction is unsurpassed, and will continue to be decades from now, even if all of the reasonably feasible long-distance collaboration technologies materialize \cite{Olson2000}. Distributing people so that they are separated by a distance greater than a short walk decreases the chances that they will visit each other dramatically \cite{Allen1977}, which according to Olson and Olson leads to losses in rapid feedback, in nuance, and in implicit cues, among other problems. As mentioned in the discussion on Extreme Programming (section \ref{sec:Extreme}), agile proposals stress these points and suggest that the whole team should sit together in an informative workspace.

There is evidence that the inverse of a maximal-isolation approach, radical co-location, is beneficial to software organizations. I discussed some of this evidence, specifically the study of Teasley \emph{et al.}\ \shortcite{Teasley2002}, in section \ref{sec:Teasley}. They studied an automobile company that decided to try ``war rooms'' for their software development projects, first as a pilot program, and later for most of their development. The war rooms had a workstation for every project member, most of whom were sitting around a large desk, with whiteboards on the walls. There were also some private cubicles available nearby, outfitted with phones and computers, so team members could choose to go there if they needed silence and privacy.

The results were strongly in favour of the pilot teams: they outperformed their company baseline by a factor of two in terms of productivity, and though a few team members were uncomfortable with the arrangement, most of them liked the war rooms, grew comfortable with their more intense interaction, and preferred them over their old cubicles.\footnote{\textbf{Contrast, Saville:} The history of co-location in Saville is more accidental, but included the same pattern of growing comfortable with intense interaction and the accessibility of team members. Saville has had three main locations throughout its life. The first one was small and had offices distributed along a ``bowling alley'' hallway. The second was one large shared room. When Saville did no longer fit in this second office and started to plan the layout of the third, several members of the organization made the point that, whatever architectural layout the offices had, the team rooms aspect had to be preserved: they became used to having teammates nearby to collaborate more intensely, and did not want to return to their first layout. Saville's approach to the use of physical space was unique in my observations.} Subsequent teams, once the program had been institutionalized, had an even better performance, improving upon the pilot teams in all productivity metrics significantly while keeping the same degree of user and team satisfaction. Furthermore, interruptions in co-located environments do not seem to be as disruptive as those in isolated environments, according to Chong and Siino \shortcite{Chong2006}: the nature of the interruptions is different and more work-related, interruptions are shorter, and several contextual variables provide potential interruptors with hints regarding the best time to interrupt their targets causing minimal disruptions.

To my knowledge, no study has yet conciliated the contrasting results represented by DeMarco and Lister with those of Teasley \emph{et al.} However, the arguments in this thesis provide an explanation for their divergence. The explanation is based on a consideration of work patterns \cite{Tesluk1997}, as discussed in section \ref{sec:WorkPatterns}. Recall that we can classify workflow dynamics as belonging to one of four categories, from Pooled workflow (where the team aggregates individual performances without the need for interaction or exchange) to Intensive workflow (where work flows between all members of the group, potentially in any direction). The competition of DeMarco and Lister is an example of Pooled workflow, while the environment in Teasley \emph{et al.}'s study corresponds mostly to the Intensive workflow dynamic. This suggests that the intensity of the workflow of a team makes certain physical layouts more convenient than others.

The taxonomy, of course, is just an abstraction, and it is unlikely that teams will fall strictly in only one category. Generally speaking, however, software projects tend to fall in the last two levels, Reciprocal and Intensive, although the exact slot for any one team depends on the specific processes and practices that it uses. There are very few software projects for which the Pooled or Sequential patterns are feasible---pure waterfalls would be an example of sequential workflow, but nobody seems to be working with pure waterfalls. In comparison, the Reciprocal workflow pattern adjusts closely to real-life waterfall and spiral project lifecycles, while the Intensive workflow pattern matches agile strategies better. In other words, the more compartmentalized and formalized work is, the lesser the need to coordinate and communicate intensely. However, if such need is present, the team benefits from physical layouts that make it easier for them to reach a robust shared understanding.

This is because team co-location fosters all four shared understanding interaction attributes. It contributes directly to synchrony and proximity, for obvious reasons. But indirectly it also helps to improve proportionality, as participants become aware of more project situations and are able to intervene if necessary, and it helps to improve maturity, as their more frequent, intense interactions fall into observable and learnable patterns more quickly.

In sum, although the research on space layout for software organizations has presented conflicting findings, the framework in this thesis offers a viable explanation for their divergence. Physical layout should be consistent with the workflow patterns of the organization; the higher the demands for intensive workflow (that is, the greater the need for robust shared understanding), the greater the need for a radically co-located area that maximizes on-the-spot coordination.



\subsection{Organizational Growth}
\label{sec:SoftwareSize}

As I discussed in section \ref{sec:Size}, it is well known that increases in organizational size lead to greater bureaucracy and formalization \cite{Blau1971,Haveman1993} and to counter-productive organizational behaviours due to de-motivation \cite{Talacchi1960}. Organizational growth also leads to a loss in cohesion: all other things being equal, a small group develops a greater cohesion than a large group simply because day-to-day experiences allow for more interactions between every group member with respect to their potential total of possible interactions \cite{Homans1950}.

Despite the loss of cohesion in larger organizations, there are certain advantages to be gained from organizational growth. The actual advantages depend on the domain of the organization; three specific advantages in the domain of software development appear to be a better role specialization, greater power to release large products relatively quickly, and leveraging software features from complementary products owned by the same organization.

From the perspective of shared understanding, however, growth is problematic. It invalidates the applicability or the usefulness of some coordination and communication mechanisms: the team can no longer sit together in the same room, code reviews do not lead to an understanding of the full architecture of the team's project, awareness dashboards become unwieldy and mostly pointless at any level beyond that of small subteams of the organization. This leads to a need to formalize, to institute processes and documentation requirements, which we have discussed at the beginning of this section to be inefficient coordination and communication mechanisms.

If the members of an organization are committed to growth, but they intend to retain access to non-scalable mechanisms, an apparent solution lies in the formation of small teams within the larger organization. The members of these teams would not need to have a particularly strong relationship with their whole organization, but merely with their team mates; clusters of highly cohesive teams could be coordinated with a more formalized organizational skeleton to achieve organizational goals, while remaining sheltered from bureaucratization.\footnote{\textbf{Contrast:} This is more or less the strategy used by both Bespoker and Saville. Both organizations are divided in groups: Saville has three major divisions of roughly similar sizes; each division has a number of projects under development in the same broad area (for instance, Financial Services). Bespoker does not have a division-based structure, but every project has its own group. In both organizations, however, some people move around between groups and divisions as needed. The larger organizations I studied seemed to have a harder time to implement this strategy, as their (large) products are heavily dependent on each other.} This is an approach used with some success by the large players of the music industry \cite{Lopes1992}. But what works for music seems difficult to enforce and achieve in the software industry: every musical production is essentially separate from each other; its linkages to other works are artistic, not concrete. The giants of the software industry (Microsoft, IBM) are notorious for the interconnectedness of their products.\footnote{\textbf{IBM:} The amount of interconnections that release engineers and project managers need to keep straight is bewildering. The release team resorts to a gross simplification of the status of each group into a ``traffic light'' state: green, yellow, or red. The latter, of course, get all the attention in status meetings, but there is enough of them that even this attention is superficial, dealing with an abstracted representation of what the problems in the group are or might be.
\par \textbf{Microsoft:} It is known (and fought in court) that Microsoft's products are extremely interconnected. An instance of the negative side of this interconnection was the resolution of one of the bugs we investigated. The bug, which only appeared sporadically (within Microsoft these are called Heisenbugs) was initially reported in one product's bug database; after some investigation the team concluded that it was not responsible for it, and blamed a different Microsoft product. Bug ownership shifted in several occasions. Only after a joint meeting of high-ranking project managers of both products (what we in our table of coordination dynamics called a ``summit'') did the groups established a joint strategy to fix the bug. I did not observe similar challenges in my case studies of smaller organizations.} In these organizations, many teams depend on the products developed by many other teams; they must therefore define deadlines, requirements, and interfaces. The organizations are forced to create support teams whose task is to ensure compliance and improvement of the organization's processes. While it is certainly possible to isolate teams in a larger organization in order to create an environment of cohesion \cite{Teasley2002,Schwaber2001}, it is an effort that runs in opposition to the trends of most large software organizations, and it is not easily accomplished.

In contrast, the problem of small software organizations is that for many domains they can only tackle relatively small problems in acceptable times \cite{Brooks1975}. There are many opportunities that are out of reach for small groups; to reach them they must grow. This growth will make them less efficient per person, but the cumulative group efforts will allow them to accomplish more as a whole. The problems that lie in this path are, first, that the organization may grow to the point where its own survival and the hierarchical advancement of its members become the overarching goals of the organization's members, rather than the accomplishment of whatever purpose the organization originally meant to address \cite{Blau1971}; and second, that a later shrinkage of the organization will probably not result in a loss of formalization: though adding people to the organization almost certainly formalizes it and makes it more rigid and less cohesive, removing people does not necessarily lead to cohesion and flexibility, as the structures, processes, and behaviours of the older, larger organization continue to influence the activities of the newer and smaller group,\footnote{\textbf{Contrast, Bespoker:} At the time of my observations, Bespoker had gone through a significant downsizing of about 40\% of its staff, mainly caused by the economic downturn. This loss was not accompanied by a reduction in the amount or kind of formalization in most groups: the same documents and processes were expected as they had been in the past. The opportunity I had to observe the consequences of such a downsizing were unique to the Bespoker case, and I do not have comparable data from other organizations.} even, potentially, influencing the behaviour of new organizations formed from the remnants of the old.\footnote{\textbf{Contrast, Bespoker:} The process- and document-heavy approach to software development in some areas of Bespoker seems to be the result of its founders being familiar with this strategy from their earlier time as software consultants in a multinational. When they created a new firm, they continued to develop software in the same fashion. Only recently have they begun to ease up some of these processes and document requirements in some of their groups. The opportunity to observe this phenomenon, again, was in my case unique to Bespoker. I do not havd comparable data from other organizations.}



\subsection{Cohesion}

So far we have discussed several common concepts in the field of software research, and we have explored their advantages and disadvantages from the point of view of the shared understanding theory summarized in section \ref{sec:Argument}. There is another important concept regarding coordination, communication, and the shared understanding theory, but it is not usually addressed in software research studies. This is the concept of group cohesion, and we have observed some of its causes and consequences in our studies. Therefore it is useful to explore cohesion in some detail.

In section \ref{sec:Cohesion} I presented Festinger's \shortcite{Festinger1950} definition of cohesion as ``the resultant of all the forces acting on the members to remain in the group.''\footnote{That section also includes a discussion on the topic of cohesion in general.} I use a similar approach to cohesion in this work, and define it as follows:

\begin{quote}
\emph{\textbf{Cohesion} is the strength or intensity of the meaningful ties between members of a group.}
\end{quote}

We have seen how, for instance, project lifecycle processes and documentation are commonly accepted approaches to establish coordination and communication in software organizations. Cohesion, in contrast, is not usually thought of as a concept that has a similar impact in terms of coordination and communication---nor on any other terms except for group morale. However, group cohesion seems to be an enabler of conditions that foster effective coordination and communication mechanisms.

The reason is that many of the synchronous, proximate, proportionate, and mature mechanisms I have discussed up to this point appear to depend on a large extent on whether the members of the organization \emph{enjoy} working in close collaboration with their peers or not. If group cohesion is not present, either by personality conflicts or interpersonal frictions, then several of our proposals are in trouble: pair programming, self-organizing teams, radical co-location, and others.\footnote{As Greg Wilson told me in a personal communication, ``radical co-location is good, except that nobody likes to be radically co-located with an asshole.''} But if the members of the organization have a strong group cohesion, they are more familiar with each other's skills, weaknesses, preferences, working styles, implicit cues, vocabulary, and areas of specialization.

There appear to be some social characteristics that enable an easier or greater development of cohesion among members of organizations. Some are summarized in table \ref{tab:SmallFirmsDetails}. Among them we have observed:

\begin{itemize}
\item \textbf{Homophily.} A phenomenon that manifests as homogeneity in a social network, caused by a natural attraction of its members to similar individuals \cite{McPherson2001}.\footnote{\textbf{Small firms:} We found several instances of both status and value homophily in our cases (Agilista's shared engineering and professional background and PhoneOffshore's prevalence of employees of the same minority group, among others). Regarding the other case studies, Bespoker has a significant minority group seemingly banding together, and at Microsoft there is a large number of mailing lists and wikis created to appeal to a huge variety of needs and wants of the members of the organization.} This homogeneity may increase the efficiency and reliability of communication, and make it easier to develop a shared understanding of every aspect of the organization.

\item \textbf{Long-term collaborations.} Long-term relationships enable a deeper understanding of the work styles of one's colleagues, and a better estimation of their capabilities.\footnote{\textbf{Small firms:} Rentcraft's product manager and project leader duo had been working together through several companies over the years, Endosymbiotic's full team forked from a different company, Bespoker's partners had been collaborating through almost two decades. I observed similarly clear long-term collaborations among employees of Saville and of Microsoft.}

\item \textbf{Rejection of radical change.} For many organizations, their current practices have been negotiated, agreed, and settled in the past; they exhibit a large degree of organizational inertia \cite{Hannan1989}. Newcomers that intend to change processes significantly, or that do not accept established practices, may be received with hostility and may not last long.\footnote{\textbf{Small firms, Endosymbiotic:} This was the case with an employee who wanted to modify the practices of the group. In my other case studies, both attempted changes and rejection of those changes were less overt.}
\end{itemize}

Lastly, let us remember that cohesion, on its own, has been shown to improve team performance in many different settings \cite{Beal2003}. More importantly, my evidence and that of others shows that cohesive teams and organizations develop shared understanding without resorting to formalization \cite{Sharp2004,Chong2007,Teasley2002,Martin2007}, and that they take advantage of the exploratory, creative, and complex nature of software development more easily than teams and organizations that adopt a process- and documentation-heavy approach.\footnote{\textbf{Contrast:} This was the case at both firms. In Saville, instances of the phenomenon were commonplace. For instance, task assignment, which usually happened every day in the morning after stand-up meetings, was fast and full of implicit information on who is the most appropriate pair to tackle a problem (considering both the short-term efficiency of assigning the most knowledgeable people and the long-term efficiency of spreading the knowledge around); and when someone was transferred from one team to another, a team member would go over the main differences between how things were done in that team in comparison to the others in a matter of only a minute or so. In Bespoker, even though some projects supposedly relied on documents to communicate requirements and priorities, these were typically put away to explain this information in terms that team members would understand most easily. In both organizations there was at least one individual who, beside their nominal responsibilities, was recognized by most as a person holding the group together: someone well connected to the owners and that could hear about important obstacles or problems and be trusted to sort them out tactfully. I did not observe people playing a similar ``jelling'' role in the other organizations I studied, though DeMarco and Lister \shortcite{DeMarco1987} report on this phenomenon as well.}

One question related to group cohesion remains: once we recognize its value, how can we foster its development? Unfortunately, this thesis does not provide an answer to this question. An emphasis on homophily in recruitment processes may yield benefits in cohesion, but its inequality implications are problematic: the minorities in a largely homogeneous organization may be left out of some opportunities available to the majority. Another strategy, as Homans \shortcite{Homans1950} observed, is to promote the frequent interactions among people, as greater frequencies of interaction lead to a greater liking of one another. It is clear that some software organizations that are aware of the importance of cohesion take good care in bringing to their groups only people who seem to harmonize with them, but their strategies to achieve this, to date, are very much an art.\footnote{\textbf{Contrast:} Both Bespoker and Saville claim to take good care of hiring staff only if some fuzzy, subjective conditions are met. Bespoker, according to one of its founders, looks for people technically capable but friendly, unassuming, and easy-going; people they would enjoy spending time with in their pizza nights or in informal chit-chats. Saville employs several tactics in the interviewing process to assess the extent to which the potential recruit is comfortable in a high-context, intensely social work environment; these tactics have to do with body language when they give the candidate a tour of the team rooms, the candidate's recollections of past experiences, and the extent to which the candidate can make all interviewers feel included in their conversations.
\par The result in both cases is a healthy and positive work environment. Several people told me they were lucky to be working there, and that it was the best place they'd been. One made a comparison with IBM, where he used to work: he said that back then he could not wait to get out of his cubicle, every day; now he actually likes to go to work. Another told me that she had left the firm at one point for another opportunity that seemed better on paper and ``came running back.''
\par In my case, and on a very subjective note, after spending a mere three weeks at each of the firms I felt a genuine and touching openness in both of them. I played euchre, table tennis, poker (I lost \$10), and Rock Band; people welcomed me in their lunch tables, shared intimate details of their personal lives, praised my home-made salsas, and sincerely invited me to continue our relationship. Both were organizations where I could see myself working happily, had my path been different, and I was sad to leave them.}
